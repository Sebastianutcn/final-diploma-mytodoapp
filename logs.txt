* 
* ==> Audit <==
* |---------|-------------------------|----------|-----------------|---------|----------------------|----------------------|
| Command |          Args           | Profile  |      User       | Version |      Start Time      |       End Time       |
|---------|-------------------------|----------|-----------------|---------|----------------------|----------------------|
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 09 Apr 24 13:28 EEST |                      |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 09 Apr 24 13:29 EEST |                      |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 09 Apr 24 13:29 EEST |                      |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 09 Apr 24 13:30 EEST | 09 Apr 24 13:31 EEST |
| stop    |                         | minikube | SEBASTIAN\babic | v1.32.0 | 09 Apr 24 21:10 EEST | 09 Apr 24 21:10 EEST |
| stop    |                         | minikube | SEBASTIAN\babic | v1.32.0 | 09 Apr 24 21:10 EEST | 09 Apr 24 21:10 EEST |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 18:50 EEST | 10 Apr 24 18:51 EEST |
| service | mytodoappnp             | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 19:38 EEST | 10 Apr 24 19:38 EEST |
| service | mytodoappnp --url       | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 19:38 EEST | 10 Apr 24 19:40 EEST |
| service | mytodoappnp --url       | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 19:40 EEST | 10 Apr 24 19:40 EEST |
| service | mytodoappnp             | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 19:40 EEST | 10 Apr 24 19:41 EEST |
| service | mytodoappnp             | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 19:45 EEST | 10 Apr 24 19:45 EEST |
| service | mytodoapp-service --url | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 20:27 EEST | 10 Apr 24 20:28 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 20:28 EEST | 10 Apr 24 20:29 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 20:29 EEST | 10 Apr 24 20:30 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 20:34 EEST | 10 Apr 24 21:01 EEST |
| stop    |                         | minikube | SEBASTIAN\babic | v1.32.0 | 10 Apr 24 21:45 EEST | 10 Apr 24 21:45 EEST |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 10:01 EEST |                      |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 10:02 EEST | 12 Apr 24 10:02 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 10:04 EEST | 12 Apr 24 10:04 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 10:05 EEST | 12 Apr 24 10:05 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 10:24 EEST | 12 Apr 24 11:08 EEST |
| delete  | --all                   | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 11:10 EEST | 12 Apr 24 11:10 EEST |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 11:11 EEST | 12 Apr 24 11:12 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 11:17 EEST |                      |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 11:18 EEST | 12 Apr 24 11:19 EEST |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 11:51 EEST |                      |
| start   |                         | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 11:51 EEST | 12 Apr 24 11:52 EEST |
| service | mytodoapp-service       | minikube | SEBASTIAN\babic | v1.32.0 | 12 Apr 24 14:46 EEST |                      |
|---------|-------------------------|----------|-----------------|---------|----------------------|----------------------|

* 
* ==> Last Start <==
* Log file created at: 2024/04/12 11:51:53
Running on machine: sebastian
Binary: Built with gc go1.21.3 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0412 11:51:53.828469   17896 out.go:296] Setting OutFile to fd 100 ...
I0412 11:51:53.828469   17896 out.go:348] isatty.IsTerminal(100) = true
I0412 11:51:53.828469   17896 out.go:309] Setting ErrFile to fd 104...
I0412 11:51:53.828469   17896 out.go:348] isatty.IsTerminal(104) = true
I0412 11:51:53.841620   17896 out.go:303] Setting JSON to false
I0412 11:51:53.845916   17896 start.go:128] hostinfo: {"hostname":"sebastian","uptime":108,"bootTime":1712911805,"procs":248,"os":"windows","platform":"Microsoft Windows 11 Pro","platformFamily":"Standalone Workstation","platformVersion":"10.0.22631.3447 Build 22631.3447","kernelVersion":"10.0.22631.3447 Build 22631.3447","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"983902dd-0956-443c-a37e-545f0a013c63"}
W0412 11:51:53.845916   17896 start.go:136] gopshost.Virtualization returned error: not implemented yet
I0412 11:51:53.848700   17896 out.go:177] üòÑ  minikube v1.32.0 on Microsoft Windows 11 Pro 10.0.22631.3447 Build 22631.3447
I0412 11:51:53.849419   17896 notify.go:220] Checking for updates...
I0412 11:51:53.849970   17896 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0412 11:51:53.850058   17896 driver.go:378] Setting default libvirt URI to qemu:///system
I0412 11:51:53.962423   17896 docker.go:122] docker version: linux-25.0.3:Docker Desktop 4.28.0 (139021)
I0412 11:51:53.966851   17896 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0412 11:51:55.725731   17896 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (1.7588804s)
I0412 11:51:55.726500   17896 info.go:266] docker info: {ID:4bbd6f1a-33e3-4d08-8b07-223a099073ba Containers:8 ContainersRunning:1 ContainersPaused:0 ContainersStopped:7 Images:7 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:43 OomKillDisable:true NGoroutines:73 SystemTime:2024-04-12 08:51:55.685759213 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:12 KernelVersion:5.15.146.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:8178094080 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.6-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.24] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.22] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.1] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.5.0]] Warnings:<nil>}}
I0412 11:51:55.728935   17896 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0412 11:51:55.730080   17896 start.go:298] selected driver: docker
I0412 11:51:55.730080   17896 start.go:902] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\babic:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0412 11:51:55.730080   17896 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0412 11:51:55.735035   17896 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0412 11:51:56.002495   17896 info.go:266] docker info: {ID:4bbd6f1a-33e3-4d08-8b07-223a099073ba Containers:8 ContainersRunning:1 ContainersPaused:0 ContainersStopped:7 Images:7 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:43 OomKillDisable:true NGoroutines:73 SystemTime:2024-04-12 08:51:55.928478852 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:12 KernelVersion:5.15.146.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:8178094080 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.6-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.24] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.22] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.1] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.5.0]] Warnings:<nil>}}
I0412 11:51:56.069616   17896 cni.go:84] Creating CNI manager for ""
I0412 11:51:56.069616   17896 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0412 11:51:56.069616   17896 start_flags.go:323] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\babic:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0412 11:51:56.071768   17896 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0412 11:51:56.072308   17896 cache.go:121] Beginning downloading kic base image for docker with docker
I0412 11:51:56.072823   17896 out.go:177] üöú  Pulling base image ...
I0412 11:51:56.072823   17896 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0412 11:51:56.072823   17896 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 in local docker daemon
I0412 11:51:56.073842   17896 preload.go:148] Found local preload: C:\Users\babic\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4
I0412 11:51:56.073842   17896 cache.go:56] Caching tarball of preloaded images
I0412 11:51:56.073842   17896 preload.go:174] Found C:\Users\babic\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0412 11:51:56.073842   17896 cache.go:59] Finished verifying existence of preloaded tar for  v1.28.3 on docker
I0412 11:51:56.073842   17896 profile.go:148] Saving config to C:\Users\babic\.minikube\profiles\minikube\config.json ...
I0412 11:51:56.186734   17896 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 in local docker daemon, skipping pull
I0412 11:51:56.186734   17896 cache.go:144] gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 exists in daemon, skipping load
I0412 11:51:56.186985   17896 cache.go:194] Successfully downloaded all kic artifacts
I0412 11:51:56.186985   17896 start.go:365] acquiring machines lock for minikube: {Name:mk7bf0f24e2a3cea7bbf73caecbaef0eb67f512c Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0412 11:51:56.187512   17896 start.go:369] acquired machines lock for "minikube" in 527.7¬µs
I0412 11:51:56.187666   17896 start.go:96] Skipping create...Using existing machine configuration
I0412 11:51:56.187666   17896 fix.go:54] fixHost starting: 
I0412 11:51:56.197375   17896 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0412 11:51:56.305167   17896 fix.go:102] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0412 11:51:56.305167   17896 fix.go:128] unexpected machine state, will restart: <nil>
I0412 11:51:56.308247   17896 out.go:177] üîÑ  Restarting existing docker container for "minikube" ...
I0412 11:51:56.313492   17896 cli_runner.go:164] Run: docker start minikube
I0412 11:51:56.694139   17896 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0412 11:51:56.799206   17896 kic.go:430] container "minikube" state is running.
I0412 11:51:56.802086   17896 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0412 11:51:56.907219   17896 profile.go:148] Saving config to C:\Users\babic\.minikube\profiles\minikube\config.json ...
I0412 11:51:56.908259   17896 machine.go:88] provisioning docker machine ...
I0412 11:51:56.908259   17896 ubuntu.go:169] provisioning hostname "minikube"
I0412 11:51:56.909917   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:57.032265   17896 main.go:141] libmachine: Using SSH client type: native
I0412 11:51:57.041554   17896 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x6447e0] 0x647320 <nil>  [] 0s} 127.0.0.1 50689 <nil> <nil>}
I0412 11:51:57.041554   17896 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0412 11:51:57.186412   17896 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0412 11:51:57.189580   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:57.295001   17896 main.go:141] libmachine: Using SSH client type: native
I0412 11:51:57.295001   17896 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x6447e0] 0x647320 <nil>  [] 0s} 127.0.0.1 50689 <nil> <nil>}
I0412 11:51:57.295001   17896 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0412 11:51:57.426739   17896 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0412 11:51:57.426739   17896 ubuntu.go:175] set auth options {CertDir:C:\Users\babic\.minikube CaCertPath:C:\Users\babic\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\babic\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\babic\.minikube\machines\server.pem ServerKeyPath:C:\Users\babic\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\babic\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\babic\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\babic\.minikube}
I0412 11:51:57.426739   17896 ubuntu.go:177] setting up certificates
I0412 11:51:57.426739   17896 provision.go:83] configureAuth start
I0412 11:51:57.428817   17896 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0412 11:51:57.534359   17896 provision.go:138] copyHostCerts
I0412 11:51:57.545801   17896 exec_runner.go:144] found C:\Users\babic\.minikube/ca.pem, removing ...
I0412 11:51:57.545801   17896 exec_runner.go:203] rm: C:\Users\babic\.minikube\ca.pem
I0412 11:51:57.545801   17896 exec_runner.go:151] cp: C:\Users\babic\.minikube\certs\ca.pem --> C:\Users\babic\.minikube/ca.pem (1074 bytes)
I0412 11:51:57.555702   17896 exec_runner.go:144] found C:\Users\babic\.minikube/cert.pem, removing ...
I0412 11:51:57.555702   17896 exec_runner.go:203] rm: C:\Users\babic\.minikube\cert.pem
I0412 11:51:57.556208   17896 exec_runner.go:151] cp: C:\Users\babic\.minikube\certs\cert.pem --> C:\Users\babic\.minikube/cert.pem (1119 bytes)
I0412 11:51:57.566968   17896 exec_runner.go:144] found C:\Users\babic\.minikube/key.pem, removing ...
I0412 11:51:57.566968   17896 exec_runner.go:203] rm: C:\Users\babic\.minikube\key.pem
I0412 11:51:57.567356   17896 exec_runner.go:151] cp: C:\Users\babic\.minikube\certs\key.pem --> C:\Users\babic\.minikube/key.pem (1675 bytes)
I0412 11:51:57.568412   17896 provision.go:112] generating server cert: C:\Users\babic\.minikube\machines\server.pem ca-key=C:\Users\babic\.minikube\certs\ca.pem private-key=C:\Users\babic\.minikube\certs\ca-key.pem org=babic.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0412 11:51:57.622852   17896 provision.go:172] copyRemoteCerts
I0412 11:51:57.630303   17896 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0412 11:51:57.631740   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:57.720024   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:51:57.817088   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\machines\server.pem --> /etc/docker/server.pem (1196 bytes)
I0412 11:51:57.845936   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0412 11:51:57.881167   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1074 bytes)
I0412 11:51:57.939830   17896 provision.go:86] duration metric: configureAuth took 513.0908ms
I0412 11:51:57.939830   17896 ubuntu.go:193] setting minikube options for container-runtime
I0412 11:51:57.940338   17896 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0412 11:51:57.942488   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:58.100669   17896 main.go:141] libmachine: Using SSH client type: native
I0412 11:51:58.101699   17896 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x6447e0] 0x647320 <nil>  [] 0s} 127.0.0.1 50689 <nil> <nil>}
I0412 11:51:58.101699   17896 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0412 11:51:58.288766   17896 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0412 11:51:58.288766   17896 ubuntu.go:71] root file system type: overlay
I0412 11:51:58.289269   17896 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0412 11:51:58.291396   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:58.453801   17896 main.go:141] libmachine: Using SSH client type: native
I0412 11:51:58.454352   17896 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x6447e0] 0x647320 <nil>  [] 0s} 127.0.0.1 50689 <nil> <nil>}
I0412 11:51:58.454488   17896 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0412 11:51:58.604102   17896 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0412 11:51:58.606244   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:58.709658   17896 main.go:141] libmachine: Using SSH client type: native
I0412 11:51:58.710484   17896 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x6447e0] 0x647320 <nil>  [] 0s} 127.0.0.1 50689 <nil> <nil>}
I0412 11:51:58.710484   17896 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0412 11:51:58.832892   17896 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0412 11:51:58.832892   17896 machine.go:91] provisioned docker machine in 1.9246332s
I0412 11:51:58.832892   17896 start.go:300] post-start starting for "minikube" (driver="docker")
I0412 11:51:58.832892   17896 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0412 11:51:58.842127   17896 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0412 11:51:58.843795   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:58.954500   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:51:59.051139   17896 ssh_runner.go:195] Run: cat /etc/os-release
I0412 11:51:59.054454   17896 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0412 11:51:59.054454   17896 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0412 11:51:59.054454   17896 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0412 11:51:59.054454   17896 info.go:137] Remote host: Ubuntu 22.04.3 LTS
I0412 11:51:59.054454   17896 filesync.go:126] Scanning C:\Users\babic\.minikube\addons for local assets ...
I0412 11:51:59.054454   17896 filesync.go:126] Scanning C:\Users\babic\.minikube\files for local assets ...
I0412 11:51:59.054957   17896 start.go:303] post-start completed in 222.0651ms
I0412 11:51:59.060927   17896 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0412 11:51:59.062561   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:59.154554   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:51:59.249395   17896 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0412 11:51:59.254189   17896 fix.go:56] fixHost completed within 3.0665232s
I0412 11:51:59.254189   17896 start.go:83] releasing machines lock for "minikube", held for 3.0666765s
I0412 11:51:59.255801   17896 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0412 11:51:59.355327   17896 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0412 11:51:59.358028   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:59.363205   17896 ssh_runner.go:195] Run: cat /version.json
I0412 11:51:59.365427   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:51:59.463118   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:51:59.478710   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:52:00.391999   17896 ssh_runner.go:235] Completed: cat /version.json: (1.0287945s)
I0412 11:52:00.391999   17896 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (1.0366725s)
I0412 11:52:00.404322   17896 ssh_runner.go:195] Run: systemctl --version
I0412 11:52:00.537359   17896 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0412 11:52:00.553787   17896 ssh_runner.go:195] Run: sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
W0412 11:52:00.564517   17896 start.go:416] unable to name loopback interface in configureRuntimes: unable to patch loopback cni config "/etc/cni/net.d/*loopback.conf*": sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;: Process exited with status 1
stdout:

stderr:
find: '\\etc\\cni\\net.d': No such file or directory
I0412 11:52:00.571028   17896 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0412 11:52:00.576708   17896 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0412 11:52:00.576708   17896 start.go:472] detecting cgroup driver to use...
I0412 11:52:00.576708   17896 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0412 11:52:00.577234   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0412 11:52:00.591787   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0412 11:52:00.604950   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0412 11:52:00.611192   17896 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0412 11:52:00.617713   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0412 11:52:00.630120   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0412 11:52:00.642410   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0412 11:52:00.655219   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0412 11:52:00.667922   17896 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0412 11:52:00.680428   17896 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0412 11:52:00.693266   17896 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0412 11:52:00.705877   17896 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0412 11:52:00.717920   17896 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0412 11:52:00.816374   17896 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0412 11:52:00.913609   17896 start.go:472] detecting cgroup driver to use...
I0412 11:52:00.913609   17896 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0412 11:52:00.920483   17896 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0412 11:52:00.930166   17896 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0412 11:52:00.938308   17896 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0412 11:52:00.948691   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0412 11:52:00.971171   17896 ssh_runner.go:195] Run: which cri-dockerd
I0412 11:52:00.982356   17896 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0412 11:52:00.988963   17896 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0412 11:52:01.005385   17896 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0412 11:52:01.103589   17896 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0412 11:52:01.160757   17896 docker.go:560] configuring docker to use "cgroupfs" as cgroup driver...
I0412 11:52:01.160757   17896 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0412 11:52:01.178088   17896 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0412 11:52:01.229497   17896 ssh_runner.go:195] Run: sudo systemctl restart docker
I0412 11:52:01.473806   17896 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0412 11:52:01.540493   17896 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0412 11:52:01.648549   17896 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0412 11:52:01.726605   17896 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0412 11:52:01.790134   17896 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0412 11:52:01.805986   17896 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0412 11:52:01.908295   17896 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0412 11:52:02.047710   17896 start.go:519] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0412 11:52:02.056029   17896 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0412 11:52:02.059399   17896 start.go:540] Will wait 60s for crictl version
I0412 11:52:02.066012   17896 ssh_runner.go:195] Run: which crictl
I0412 11:52:02.075246   17896 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0412 11:52:02.160653   17896 start.go:556] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.7
RuntimeApiVersion:  v1
I0412 11:52:02.162250   17896 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0412 11:52:02.214966   17896 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0412 11:52:02.233848   17896 out.go:204] üê≥  Preparing Kubernetes v1.28.3 on Docker 24.0.7 ...
I0412 11:52:02.235924   17896 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0412 11:52:02.400164   17896 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0412 11:52:02.411755   17896 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0412 11:52:02.415815   17896 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0412 11:52:02.424998   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0412 11:52:02.523292   17896 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0412 11:52:02.524986   17896 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0412 11:52:02.542022   17896 docker.go:671] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0412 11:52:02.542022   17896 docker.go:601] Images already preloaded, skipping extraction
I0412 11:52:02.543659   17896 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0412 11:52:02.555993   17896 docker.go:671] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0412 11:52:02.555993   17896 cache_images.go:84] Images are preloaded, skipping loading
I0412 11:52:02.558137   17896 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0412 11:52:02.688394   17896 cni.go:84] Creating CNI manager for ""
I0412 11:52:02.688394   17896 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0412 11:52:02.688394   17896 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0412 11:52:02.688394   17896 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.28.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0412 11:52:02.688898   17896 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.28.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0412 11:52:02.688898   17896 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.28.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0412 11:52:02.695592   17896 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.28.3
I0412 11:52:02.702106   17896 binaries.go:44] Found k8s binaries, skipping transfer
I0412 11:52:02.708639   17896 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0412 11:52:02.716370   17896 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0412 11:52:02.726979   17896 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0412 11:52:02.738591   17896 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2091 bytes)
I0412 11:52:02.755932   17896 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0412 11:52:02.759308   17896 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0412 11:52:02.767091   17896 certs.go:56] Setting up C:\Users\babic\.minikube\profiles\minikube for IP: 192.168.49.2
I0412 11:52:02.767091   17896 certs.go:190] acquiring lock for shared ca certs: {Name:mkd0f74002e006e48a9d3173fd411f908d03f10c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0412 11:52:02.774650   17896 certs.go:199] skipping minikubeCA CA generation: C:\Users\babic\.minikube\ca.key
I0412 11:52:02.788270   17896 certs.go:199] skipping proxyClientCA CA generation: C:\Users\babic\.minikube\proxy-client-ca.key
I0412 11:52:02.788796   17896 certs.go:315] skipping minikube-user signed cert generation: C:\Users\babic\.minikube\profiles\minikube\client.key
I0412 11:52:02.803289   17896 certs.go:315] skipping minikube signed cert generation: C:\Users\babic\.minikube\profiles\minikube\apiserver.key.dd3b5fb2
I0412 11:52:02.818415   17896 certs.go:315] skipping aggregator signed cert generation: C:\Users\babic\.minikube\profiles\minikube\proxy-client.key
I0412 11:52:02.821992   17896 certs.go:437] found cert: C:\Users\babic\.minikube\certs\C:\Users\babic\.minikube\certs\ca-key.pem (1679 bytes)
I0412 11:52:02.821992   17896 certs.go:437] found cert: C:\Users\babic\.minikube\certs\C:\Users\babic\.minikube\certs\ca.pem (1074 bytes)
I0412 11:52:02.821992   17896 certs.go:437] found cert: C:\Users\babic\.minikube\certs\C:\Users\babic\.minikube\certs\cert.pem (1119 bytes)
I0412 11:52:02.822988   17896 certs.go:437] found cert: C:\Users\babic\.minikube\certs\C:\Users\babic\.minikube\certs\key.pem (1675 bytes)
I0412 11:52:02.824085   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0412 11:52:02.841938   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0412 11:52:02.856482   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0412 11:52:02.870613   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0412 11:52:02.884567   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0412 11:52:02.898871   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0412 11:52:02.913331   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0412 11:52:02.928022   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0412 11:52:02.944011   17896 ssh_runner.go:362] scp C:\Users\babic\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0412 11:52:02.959960   17896 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (740 bytes)
I0412 11:52:02.978178   17896 ssh_runner.go:195] Run: openssl version
I0412 11:52:02.991816   17896 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0412 11:52:03.006119   17896 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0412 11:52:03.009354   17896 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Apr  9 10:31 /usr/share/ca-certificates/minikubeCA.pem
I0412 11:52:03.016004   17896 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0412 11:52:03.030762   17896 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0412 11:52:03.044526   17896 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0412 11:52:03.054538   17896 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0412 11:52:03.066576   17896 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0412 11:52:03.079199   17896 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0412 11:52:03.093147   17896 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0412 11:52:03.105411   17896 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0412 11:52:03.118324   17896 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0412 11:52:03.124428   17896 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\babic:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0412 11:52:03.127627   17896 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0412 11:52:03.150163   17896 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0412 11:52:03.157673   17896 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I0412 11:52:03.157673   17896 kubeadm.go:636] restartCluster start
I0412 11:52:03.164216   17896 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0412 11:52:03.169960   17896 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0412 11:52:03.172143   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0412 11:52:03.278900   17896 kubeconfig.go:92] found "minikube" server: "https://127.0.0.1:52495"
I0412 11:52:03.278900   17896 kubeconfig.go:135] verify returned: got: 127.0.0.1:52495, want: 127.0.0.1:50693
I0412 11:52:03.279409   17896 lock.go:35] WriteFile acquiring C:\Users\babic\.kube\config: {Name:mkc23197cbdf86bcf37ef70bbafefdf009aea4c6 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0412 11:52:03.300536   17896 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0412 11:52:03.307882   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:03.314636   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:03.325623   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:03.325623   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:03.333459   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:03.341939   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:03.852243   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:03.865650   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:03.873651   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:04.350085   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:04.357087   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:04.364536   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:04.847237   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:04.854366   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:04.863517   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:05.346260   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:05.354574   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:05.364517   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:05.851202   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:05.860920   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:05.873819   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:06.360921   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:06.372525   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:06.384380   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:06.846009   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:06.855775   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:06.862664   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:07.356631   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:07.363604   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:07.380247   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:07.848006   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:07.858122   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:07.865446   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:08.342333   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:08.352599   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:08.359161   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:08.845151   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:08.862038   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:08.883315   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:09.348785   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:09.357753   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:09.370160   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:09.845899   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:09.856600   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:09.866344   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:10.342192   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:10.358744   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:10.365846   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:10.853309   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:10.859845   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:10.870349   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:11.344994   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:11.350937   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:11.359444   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:11.855041   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:11.868340   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:11.877149   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:12.353983   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:12.367063   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:12.374444   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:12.848518   17896 api_server.go:166] Checking apiserver status ...
I0412 11:52:12.861209   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0412 11:52:12.872257   17896 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0412 11:52:13.314732   17896 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I0412 11:52:13.314732   17896 kubeadm.go:1128] stopping kube-system containers ...
I0412 11:52:13.317994   17896 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0412 11:52:13.340401   17896 docker.go:469] Stopping containers: [db6cab21b562 5ee7096c69a6 f331e1103653 3710f7734d7c d5d74ba29d5e 6102195bf84d f7bc10590cea df0cb92901ed c671d022ec23 2aa3a729c51a 06ed8cfa9755 52d903e4a529 8dc797bf94f5 b16af9784555 73c64e75d03c 1f0e761e745c 517d6b16abf2 5ead4d6f773c 5ff337bc37e6 defbb2f436d0 20988dcf9766 1b86a3612115 ed13f3394808 c55ab80b4ca5 006e7f933db7 d2dd50c21a69 58629e8c4992]
I0412 11:52:13.343078   17896 ssh_runner.go:195] Run: docker stop db6cab21b562 5ee7096c69a6 f331e1103653 3710f7734d7c d5d74ba29d5e 6102195bf84d f7bc10590cea df0cb92901ed c671d022ec23 2aa3a729c51a 06ed8cfa9755 52d903e4a529 8dc797bf94f5 b16af9784555 73c64e75d03c 1f0e761e745c 517d6b16abf2 5ead4d6f773c 5ff337bc37e6 defbb2f436d0 20988dcf9766 1b86a3612115 ed13f3394808 c55ab80b4ca5 006e7f933db7 d2dd50c21a69 58629e8c4992
I0412 11:52:13.370166   17896 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0412 11:52:13.391804   17896 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0412 11:52:13.402382   17896 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5643 Apr 12 08:11 /etc/kubernetes/admin.conf
-rw------- 1 root root 5656 Apr 12 08:18 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 1971 Apr 12 08:12 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5604 Apr 12 08:18 /etc/kubernetes/scheduler.conf

I0412 11:52:13.409441   17896 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0412 11:52:13.427912   17896 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0412 11:52:13.443821   17896 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0412 11:52:13.454537   17896 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I0412 11:52:13.461497   17896 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0412 11:52:13.478165   17896 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0412 11:52:13.487236   17896 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I0412 11:52:13.494367   17896 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0412 11:52:13.507599   17896 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0412 11:52:13.514637   17896 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0412 11:52:13.514637   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0412 11:52:13.633336   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0412 11:52:14.038020   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0412 11:52:14.168748   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0412 11:52:14.206426   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0412 11:52:14.237020   17896 api_server.go:52] waiting for apiserver process to appear ...
I0412 11:52:14.243820   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0412 11:52:14.256870   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0412 11:52:14.781606   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0412 11:52:15.279189   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0412 11:52:15.335272   17896 api_server.go:72] duration metric: took 1.0982514s to wait for apiserver process to appear ...
I0412 11:52:15.335272   17896 api_server.go:88] waiting for apiserver healthz status ...
I0412 11:52:15.335272   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:15.338146   17896 api_server.go:269] stopped: https://127.0.0.1:50693/healthz: Get "https://127.0.0.1:50693/healthz": EOF
I0412 11:52:15.338146   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:15.340947   17896 api_server.go:269] stopped: https://127.0.0.1:50693/healthz: Get "https://127.0.0.1:50693/healthz": EOF
I0412 11:52:15.849076   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:17.850502   17896 api_server.go:279] https://127.0.0.1:50693/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0412 11:52:17.850502   17896 api_server.go:103] status: https://127.0.0.1:50693/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0412 11:52:17.850502   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:17.949327   17896 api_server.go:279] https://127.0.0.1:50693/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0412 11:52:17.949327   17896 api_server.go:103] status: https://127.0.0.1:50693/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0412 11:52:18.342073   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:18.347572   17896 api_server.go:279] https://127.0.0.1:50693/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0412 11:52:18.347572   17896 api_server.go:103] status: https://127.0.0.1:50693/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0412 11:52:18.845472   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:18.852162   17896 api_server.go:279] https://127.0.0.1:50693/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0412 11:52:18.852162   17896 api_server.go:103] status: https://127.0.0.1:50693/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0412 11:52:19.342060   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:19.349151   17896 api_server.go:279] https://127.0.0.1:50693/healthz returned 200:
ok
I0412 11:52:19.359440   17896 api_server.go:141] control plane version: v1.28.3
I0412 11:52:19.359440   17896 api_server.go:131] duration metric: took 4.0241682s to wait for apiserver health ...
I0412 11:52:19.359440   17896 cni.go:84] Creating CNI manager for ""
I0412 11:52:19.359440   17896 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0412 11:52:19.359978   17896 out.go:177] üîó  Configuring bridge CNI (Container Networking Interface) ...
I0412 11:52:19.371700   17896 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0412 11:52:19.381537   17896 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0412 11:52:19.394241   17896 system_pods.go:43] waiting for kube-system pods to appear ...
I0412 11:52:19.401368   17896 system_pods.go:59] 7 kube-system pods found
I0412 11:52:19.401368   17896 system_pods.go:61] "coredns-5dd5756b68-fhf4r" [3606f266-4c38-477b-85e6-20e2b69a2036] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0412 11:52:19.401368   17896 system_pods.go:61] "etcd-minikube" [777c9b65-12ab-40a7-81ee-5c5a004a9c9e] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0412 11:52:19.401368   17896 system_pods.go:61] "kube-apiserver-minikube" [6d7296d1-2df4-41db-b697-1e76c581d824] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0412 11:52:19.401368   17896 system_pods.go:61] "kube-controller-manager-minikube" [60dd7191-2d93-451c-83b8-01e12f653b3e] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0412 11:52:19.401368   17896 system_pods.go:61] "kube-proxy-fg4hl" [941ae0c6-4e2e-4775-8de3-0e6e3b6a6f5b] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0412 11:52:19.401368   17896 system_pods.go:61] "kube-scheduler-minikube" [7d777a36-5b17-44e2-98e4-94f8eaf2272e] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0412 11:52:19.401368   17896 system_pods.go:61] "storage-provisioner" [ff5b4168-e01f-4994-9a60-178052ec9e5d] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0412 11:52:19.401368   17896 system_pods.go:74] duration metric: took 7.1267ms to wait for pod list to return data ...
I0412 11:52:19.401368   17896 node_conditions.go:102] verifying NodePressure condition ...
I0412 11:52:19.436008   17896 node_conditions.go:122] node storage ephemeral capacity is 1055762868Ki
I0412 11:52:19.436008   17896 node_conditions.go:123] node cpu capacity is 12
I0412 11:52:19.436008   17896 node_conditions.go:105] duration metric: took 34.6402ms to run NodePressure ...
I0412 11:52:19.436008   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0412 11:52:19.597974   17896 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0412 11:52:19.605302   17896 ops.go:34] apiserver oom_adj: -16
I0412 11:52:19.605302   17896 kubeadm.go:640] restartCluster took 16.4476288s
I0412 11:52:19.605302   17896 kubeadm.go:406] StartCluster complete in 16.4808739s
I0412 11:52:19.605302   17896 settings.go:142] acquiring lock: {Name:mk5ef5945ab71efd4225a3f15501e8bcfa1d7793 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0412 11:52:19.605839   17896 settings.go:150] Updating kubeconfig:  C:\Users\babic\.kube\config
I0412 11:52:19.606372   17896 lock.go:35] WriteFile acquiring C:\Users\babic\.kube\config: {Name:mkc23197cbdf86bcf37ef70bbafefdf009aea4c6 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0412 11:52:19.607421   17896 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0412 11:52:19.607421   17896 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false]
I0412 11:52:19.607421   17896 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0412 11:52:19.607421   17896 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0412 11:52:19.607421   17896 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W0412 11:52:19.607421   17896 addons.go:240] addon storage-provisioner should already be in state true
I0412 11:52:19.607421   17896 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0412 11:52:19.607421   17896 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0412 11:52:19.607421   17896 host.go:66] Checking if "minikube" exists ...
I0412 11:52:19.618546   17896 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0412 11:52:19.619077   17896 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0412 11:52:19.636870   17896 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0412 11:52:19.636870   17896 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0412 11:52:19.637398   17896 out.go:177] üîé  Verifying Kubernetes components...
I0412 11:52:19.650650   17896 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0412 11:52:19.734271   17896 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0412 11:52:19.734802   17896 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0412 11:52:19.734802   17896 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0412 11:52:19.738717   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:52:19.768459   17896 addons.go:231] Setting addon default-storageclass=true in "minikube"
W0412 11:52:19.768459   17896 addons.go:240] addon default-storageclass should already be in state true
I0412 11:52:19.768995   17896 host.go:66] Checking if "minikube" exists ...
I0412 11:52:19.794718   17896 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0412 11:52:19.882585   17896 start.go:899] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0412 11:52:19.886281   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0412 11:52:19.902793   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:52:19.932269   17896 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0412 11:52:19.932269   17896 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0412 11:52:19.934700   17896 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0412 11:52:20.021647   17896 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0412 11:52:20.021647   17896 api_server.go:52] waiting for apiserver process to appear ...
I0412 11:52:20.035875   17896 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0412 11:52:20.066348   17896 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50689 SSHKeyPath:C:\Users\babic\.minikube\machines\minikube\id_rsa Username:docker}
I0412 11:52:20.187106   17896 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0412 11:52:20.540822   17896 api_server.go:72] duration metric: took 903.9525ms to wait for apiserver process to appear ...
I0412 11:52:20.540822   17896 api_server.go:88] waiting for apiserver healthz status ...
I0412 11:52:20.540822   17896 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50693/healthz ...
I0412 11:52:20.547986   17896 api_server.go:279] https://127.0.0.1:50693/healthz returned 200:
ok
I0412 11:52:20.549565   17896 api_server.go:141] control plane version: v1.28.3
I0412 11:52:20.549565   17896 api_server.go:131] duration metric: took 8.7425ms to wait for apiserver health ...
I0412 11:52:20.549565   17896 system_pods.go:43] waiting for kube-system pods to appear ...
I0412 11:52:20.550630   17896 out.go:177] üåü  Enabled addons: storage-provisioner, default-storageclass
I0412 11:52:20.551154   17896 addons.go:502] enable addons completed in 943.7331ms: enabled=[storage-provisioner default-storageclass]
I0412 11:52:20.554331   17896 system_pods.go:59] 7 kube-system pods found
I0412 11:52:20.554331   17896 system_pods.go:61] "coredns-5dd5756b68-fhf4r" [3606f266-4c38-477b-85e6-20e2b69a2036] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0412 11:52:20.554331   17896 system_pods.go:61] "etcd-minikube" [777c9b65-12ab-40a7-81ee-5c5a004a9c9e] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0412 11:52:20.554331   17896 system_pods.go:61] "kube-apiserver-minikube" [6d7296d1-2df4-41db-b697-1e76c581d824] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0412 11:52:20.554331   17896 system_pods.go:61] "kube-controller-manager-minikube" [60dd7191-2d93-451c-83b8-01e12f653b3e] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0412 11:52:20.554331   17896 system_pods.go:61] "kube-proxy-fg4hl" [941ae0c6-4e2e-4775-8de3-0e6e3b6a6f5b] Running
I0412 11:52:20.554331   17896 system_pods.go:61] "kube-scheduler-minikube" [7d777a36-5b17-44e2-98e4-94f8eaf2272e] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0412 11:52:20.554331   17896 system_pods.go:61] "storage-provisioner" [ff5b4168-e01f-4994-9a60-178052ec9e5d] Running
I0412 11:52:20.554331   17896 system_pods.go:74] duration metric: took 4.7661ms to wait for pod list to return data ...
I0412 11:52:20.554331   17896 kubeadm.go:581] duration metric: took 917.4611ms to wait for : map[apiserver:true system_pods:true] ...
I0412 11:52:20.554331   17896 node_conditions.go:102] verifying NodePressure condition ...
I0412 11:52:20.558262   17896 node_conditions.go:122] node storage ephemeral capacity is 1055762868Ki
I0412 11:52:20.558262   17896 node_conditions.go:123] node cpu capacity is 12
I0412 11:52:20.558262   17896 node_conditions.go:105] duration metric: took 3.9317ms to run NodePressure ...
I0412 11:52:20.558262   17896 start.go:228] waiting for startup goroutines ...
I0412 11:52:20.558262   17896 start.go:233] waiting for cluster config update ...
I0412 11:52:20.558262   17896 start.go:242] writing updated cluster config ...
I0412 11:52:20.566979   17896 ssh_runner.go:195] Run: rm -f paused
I0412 11:52:20.652340   17896 start.go:600] kubectl: 1.29.1, cluster: 1.28.3 (minor skew: 1)
I0412 11:52:20.652850   17896 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.359012648Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.377539615Z" level=info msg="Loading containers: done."
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.391326349Z" level=warning msg="WARNING: No blkio throttle.read_bps_device support"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.391361556Z" level=warning msg="WARNING: No blkio throttle.write_bps_device support"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.391365290Z" level=warning msg="WARNING: No blkio throttle.read_iops_device support"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.391367371Z" level=warning msg="WARNING: No blkio throttle.write_iops_device support"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.391378793Z" level=info msg="Docker daemon" commit=311b9ff graphdriver=overlay2 version=24.0.7
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.391410383Z" level=info msg="Daemon has completed initialization"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.461767616Z" level=info msg="API listen on /var/run/docker.sock"
Apr 12 08:52:01 minikube dockerd[938]: time="2024-04-12T08:52:01.461830543Z" level=info msg="API listen on [::]:2376"
Apr 12 08:52:01 minikube systemd[1]: Started Docker Application Container Engine.
Apr 12 08:52:01 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Start docker client with request timeout 0s"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Hairpin mode is set to hairpin-veth"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Loaded network plugin cni"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Docker cri networking managed by network plugin cni"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Docker Info: &{ID:46083d5f-cfc7-458e-b8a9-d8a5fac7abab Containers:27 ContainersRunning:0 ContainersPaused:0 ContainersStopped:27 Images:8 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:25 OomKillDisable:true NGoroutines:35 SystemTime:2024-04-12T08:52:02.04095039Z LoggingDriver:json-file CgroupDriver:cgroupfs CgroupVersion:1 NEventsListener:0 KernelVersion:5.15.146.1-microsoft-standard-WSL2 OperatingSystem:Ubuntu 22.04.3 LTS (containerized) OSVersion:22.04 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc000221f80 NCPU:12 MemTotal:8178094080 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy:control-plane.minikube.internal Name:minikube Labels:[provider=docker] ExperimentalBuild:false ServerVersion:24.0.7 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[] Shim:<nil>} runc:{Path:runc Args:[] Shim:<nil>}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:<nil> Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:61f9fd88f79f081d64d6fa3bb1a0dc71ec870523 Expected:61f9fd88f79f081d64d6fa3bb1a0dc71ec870523} RuncCommit:{ID:v1.1.9-0-gccaecfc Expected:v1.1.9-0-gccaecfc} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin] ProductLicense: DefaultAddressPools:[] Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support]}"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Setting cgroupDriver cgroupfs"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Apr 12 08:52:02 minikube cri-dockerd[1165]: time="2024-04-12T08:52:02Z" level=info msg="Start cri-dockerd grpc backend"
Apr 12 08:52:02 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Apr 12 08:52:14 minikube cri-dockerd[1165]: time="2024-04-12T08:52:14Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"coredns-5dd5756b68-fhf4r_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"d5d74ba29d5ee54bd481fc459ebbcca744f4727964f560512fd8fc30cba4553b\""
Apr 12 08:52:14 minikube cri-dockerd[1165]: time="2024-04-12T08:52:14Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"coredns-5dd5756b68-fhf4r_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"5ff337bc37e6f3896b2434e2811abe858940664d8341115cd5824654722f4f85\""
Apr 12 08:52:14 minikube cri-dockerd[1165]: time="2024-04-12T08:52:14Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"d2dd50c21a69b8848a0c96b1ed755a73da5db88082c6d1db249f92261e7fc3a5\". Proceed without further sandbox information."
Apr 12 08:52:14 minikube cri-dockerd[1165]: time="2024-04-12T08:52:14Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"006e7f933db770d59c5b39cfb469cc6af45cd4bff5014ac4f7e6efbfbb285bbb\". Proceed without further sandbox information."
Apr 12 08:52:14 minikube cri-dockerd[1165]: time="2024-04-12T08:52:14Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"c55ab80b4ca585105a8bdd51601015f87e3aeac468a6c3aeba83e2e1facb6245\". Proceed without further sandbox information."
Apr 12 08:52:14 minikube cri-dockerd[1165]: time="2024-04-12T08:52:14Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"58629e8c49922ae7a07668c54ea6ca18e44ad094083664d74f144f51c1313e30\". Proceed without further sandbox information."
Apr 12 08:52:15 minikube cri-dockerd[1165]: time="2024-04-12T08:52:15Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/a111e97063f04807fde4bba842fe7aeb4847b5b06e93bc4603a31f362f03f4bd/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:15 minikube cri-dockerd[1165]: time="2024-04-12T08:52:15Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/6e0359cc57a259e2529300e3b079e30ebbf94f424ab1e891807186ed388790ad/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:15 minikube cri-dockerd[1165]: time="2024-04-12T08:52:15Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/05b6defb98d6e4a446b331c6f7fcd6ae1df5853c5b1a74b762a49269224aecaa/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:15 minikube cri-dockerd[1165]: time="2024-04-12T08:52:15Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/70bfaef89d9f831a8f7f498fb364222b35e6d8d1f9a6215667c5c310f72f8e16/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:15 minikube cri-dockerd[1165]: time="2024-04-12T08:52:15Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"coredns-5dd5756b68-fhf4r_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"d5d74ba29d5ee54bd481fc459ebbcca744f4727964f560512fd8fc30cba4553b\""
Apr 12 08:52:18 minikube cri-dockerd[1165]: time="2024-04-12T08:52:18Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Apr 12 08:52:18 minikube cri-dockerd[1165]: time="2024-04-12T08:52:18Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/5f8fbb010c2c1c24d377701a3d6f2bad50a87e4c30b09fbf247222a60c4beed5/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:18 minikube cri-dockerd[1165]: time="2024-04-12T08:52:18Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/633ec04534403b5068403a6a6dd28a4237436cf8014ae4615a3ba5d068835da8/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:19 minikube cri-dockerd[1165]: time="2024-04-12T08:52:19Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/dd04555b2fa03ca04641c33174eba06f1db93b71747a16222224d83023ed50ce/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Apr 12 08:52:29 minikube dockerd[938]: time="2024-04-12T08:52:29.477945584Z" level=info msg="ignoring event" container=18f1d25b721b4e424f01b591c673b7e274c68bc4d0cc627a79d48ee309b876a7 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Apr 12 11:45:57 minikube cri-dockerd[1165]: time="2024-04-12T11:45:57Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/f69a43742994255caca2bf9dee8b503cddb3ea4aff7089164afdfb720b51ee0b/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Apr 12 11:45:57 minikube cri-dockerd[1165]: time="2024-04-12T11:45:57Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1582ceb753c19b2eed5903f464e327f3dfc23ed5c8f9f7f363ac5902e108e09a/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Apr 12 11:45:57 minikube cri-dockerd[1165]: time="2024-04-12T11:45:57Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/5807f84d43807d8558ff3c6058db9fc292b2623ddd2532240c04c3a3a08bc01c/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Apr 12 11:45:57 minikube dockerd[938]: time="2024-04-12T11:45:57.838441902Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:45:57 minikube dockerd[938]: time="2024-04-12T11:45:57.847117651Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:45:58 minikube dockerd[938]: time="2024-04-12T11:45:58.397579157Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:45:58 minikube dockerd[938]: time="2024-04-12T11:45:58.400961796Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:45:58 minikube dockerd[938]: time="2024-04-12T11:45:58.961258619Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:45:58 minikube dockerd[938]: time="2024-04-12T11:45:58.966828807Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:10 minikube dockerd[938]: time="2024-04-12T11:46:10.644023500Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:10 minikube dockerd[938]: time="2024-04-12T11:46:10.648094059Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:11 minikube dockerd[938]: time="2024-04-12T11:46:11.732235921Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:11 minikube dockerd[938]: time="2024-04-12T11:46:11.735640083Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:12 minikube dockerd[938]: time="2024-04-12T11:46:12.602476827Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:12 minikube dockerd[938]: time="2024-04-12T11:46:12.608978716Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:36 minikube dockerd[938]: time="2024-04-12T11:46:36.608391910Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:36 minikube dockerd[938]: time="2024-04-12T11:46:36.610541559Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:37 minikube dockerd[938]: time="2024-04-12T11:46:37.621893717Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:37 minikube dockerd[938]: time="2024-04-12T11:46:37.627090487Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:40 minikube dockerd[938]: time="2024-04-12T11:46:40.638725097Z" level=info msg="Attempting next endpoint for pull after error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"
Apr 12 11:46:40 minikube dockerd[938]: time="2024-04-12T11:46:40.642459540Z" level=error msg="Handler for POST /v1.42/images/create returned error: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
0a29f0b3fbd2f       6e38f40d628db       3 hours ago         Running             storage-provisioner       5                   5f8fbb010c2c1       storage-provisioner
48e39ed52aea3       ead0a4a53df89       3 hours ago         Running             coredns                   2                   dd04555b2fa03       coredns-5dd5756b68-fhf4r
18f1d25b721b4       6e38f40d628db       3 hours ago         Exited              storage-provisioner       4                   5f8fbb010c2c1       storage-provisioner
0170b62d1a5b1       bfc896cf80fba       3 hours ago         Running             kube-proxy                2                   633ec04534403       kube-proxy-fg4hl
bb9a0e8df7c69       10baa1ca17068       3 hours ago         Running             kube-controller-manager   2                   6e0359cc57a25       kube-controller-manager-minikube
8f1d95252ddf0       6d1b4fd1b182d       3 hours ago         Running             kube-scheduler            2                   70bfaef89d9f8       kube-scheduler-minikube
827129707d506       5374347291230       3 hours ago         Running             kube-apiserver            2                   a111e97063f04       kube-apiserver-minikube
7624ffb81b16b       73deb9a3f7025       3 hours ago         Running             etcd                      2                   05b6defb98d6e       etcd-minikube
5ee7096c69a67       ead0a4a53df89       3 hours ago         Exited              coredns                   1                   d5d74ba29d5ee       coredns-5dd5756b68-fhf4r
3710f7734d7c9       bfc896cf80fba       3 hours ago         Exited              kube-proxy                1                   6102195bf84d3       kube-proxy-fg4hl
df0cb92901ed9       10baa1ca17068       3 hours ago         Exited              kube-controller-manager   1                   52d903e4a5293       kube-controller-manager-minikube
c671d022ec239       73deb9a3f7025       3 hours ago         Exited              etcd                      1                   b16af97845552       etcd-minikube
2aa3a729c51ae       6d1b4fd1b182d       3 hours ago         Exited              kube-scheduler            1                   73c64e75d03c9       kube-scheduler-minikube
06ed8cfa9755b       5374347291230       3 hours ago         Exited              kube-apiserver            1                   8dc797bf94f55       kube-apiserver-minikube

* 
* ==> coredns [48e39ed52aea] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.10.1
linux/amd64, go1.20, 055b2c3
[INFO] 127.0.0.1:52164 - 35185 "HINFO IN 6160837354499382552.7640803277219052054. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.047499528s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[WARNING] plugin/kubernetes: Kubernetes API connection failure: Get "https://10.96.0.1:443/version": net/http: TLS handshake timeout

* 
* ==> coredns [5ee7096c69a6] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.10.1
linux/amd64, go1.20, 055b2c3
[INFO] 127.0.0.1:46443 - 16969 "HINFO IN 8630520724286529858.1330209442392359452. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.21554968s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=8220a6eb95f0a4d75f7f2d7b14cef975f050512d
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2024_04_12T11_12_01_0700
                    minikube.k8s.io/version=v1.32.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Fri, 12 Apr 2024 08:11:57 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Fri, 12 Apr 2024 11:46:59 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Fri, 12 Apr 2024 11:46:40 +0000   Fri, 12 Apr 2024 08:11:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Fri, 12 Apr 2024 11:46:40 +0000   Fri, 12 Apr 2024 08:11:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Fri, 12 Apr 2024 11:46:40 +0000   Fri, 12 Apr 2024 08:11:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Fri, 12 Apr 2024 11:46:40 +0000   Fri, 12 Apr 2024 08:12:02 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                12
  ephemeral-storage:  1055762868Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             7986420Ki
  pods:               110
Allocatable:
  cpu:                12
  ephemeral-storage:  1055762868Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             7986420Ki
  pods:               110
System Info:
  Machine ID:                 2ccea0166b4240dcb2cad16b1ea3fcfc
  System UUID:                2ccea0166b4240dcb2cad16b1ea3fcfc
  Boot ID:                    c1f96206-de9b-4667-8ae4-2e1d36fd7c3b
  Kernel Version:             5.15.146.1-microsoft-standard-WSL2
  OS Image:                   Ubuntu 22.04.3 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://24.0.7
  Kubelet Version:            v1.28.3
  Kube-Proxy Version:         v1.28.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (10 in total)
  Namespace                   Name                                    CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                    ------------  ----------  ---------------  -------------  ---
  default                     mytodoapp-deployment-9b897698f-bbwvg    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         72s
  default                     mytodoapp-deployment-9b897698f-ntsj2    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         72s
  default                     mytodoapp-deployment-9b897698f-vf5jt    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         72s
  kube-system                 coredns-5dd5756b68-fhf4r                100m (0%!)(MISSING)     0 (0%!)(MISSING)      70Mi (0%!)(MISSING)        170Mi (2%!)(MISSING)     3h34m
  kube-system                 etcd-minikube                           100m (0%!)(MISSING)     0 (0%!)(MISSING)      100Mi (1%!)(MISSING)       0 (0%!)(MISSING)         3h35m
  kube-system                 kube-apiserver-minikube                 250m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3h35m
  kube-system                 kube-controller-manager-minikube        200m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3h35m
  kube-system                 kube-proxy-fg4hl                        0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3h34m
  kube-system                 kube-scheduler-minikube                 100m (0%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3h35m
  kube-system                 storage-provisioner                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3h35m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (6%!)(MISSING)   0 (0%!)(MISSING)
  memory             170Mi (2%!)(MISSING)  170Mi (2%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:              <none>

* 
* ==> dmesg <==
* [  +0.092183] FS-Cache: Duplicate cookie detected
[  +0.000291] FS-Cache: O-cookie c=00000008 [p=00000002 fl=222 nc=0 na=1]
[  +0.000276] FS-Cache: O-cookie d=000000000b12a22e{9P.session} n=00000000494c02da
[  +0.000299] FS-Cache: O-key=[10] '34323934393337353231'
[  +0.000259] FS-Cache: N-cookie c=00000009 [p=00000002 fl=2 nc=0 na=1]
[  +0.000261] FS-Cache: N-cookie d=000000000b12a22e{9P.session} n=000000005fdc01d3
[  +0.000333] FS-Cache: N-key=[10] '34323934393337353231'
[  +0.017760] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000006]  failed 2
[  +0.008230] FS-Cache: Duplicate cookie detected
[  +0.000417] FS-Cache: O-cookie c=0000000a [p=00000002 fl=222 nc=0 na=1]
[  +0.000849] FS-Cache: O-cookie d=000000000b12a22e{9P.session} n=000000007d30f676
[  +0.000915] FS-Cache: O-key=[10] '34323934393337353234'
[  +0.000360] FS-Cache: N-cookie c=0000000b [p=00000002 fl=2 nc=0 na=1]
[  +0.000532] FS-Cache: N-cookie d=000000000b12a22e{9P.session} n=000000002b40471d
[  +0.000695] FS-Cache: N-key=[10] '34323934393337353234'
[  +0.004360] WSL (1) WARNING: /usr/share/zoneinfo/Europe/Bucharest not found. Is the tzdata package installed?
[  +0.148867] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000571] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000359] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000411] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +0.000777] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000410] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000384] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000405] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +1.417503] /sbin/ldconfig: 
[  +0.000005] /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link

[  +0.016470] FS-Cache: Duplicate cookie detected
[  +0.001688] FS-Cache: O-cookie c=00000015 [p=00000002 fl=222 nc=0 na=1]
[  +0.001008] FS-Cache: O-cookie d=000000000b12a22e{9P.session} n=000000002082fb11
[  +0.001179] FS-Cache: O-key=[10] '34323934393337363833'
[  +0.000489] FS-Cache: N-cookie c=00000016 [p=00000002 fl=2 nc=0 na=1]
[  +0.000493] FS-Cache: N-cookie d=000000000b12a22e{9P.session} n=000000004bdfe87e
[  +0.000704] FS-Cache: N-key=[10] '34323934393337363833'
[  +0.006937] WSL (2) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.003367] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.003038] WSL (1) ERROR: ConfigMountFsTab:2589: Processing fstab with mount -a failed.
[  +0.002392] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000004]  failed 2
[  +0.006767] WSL (3) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001424] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.004566] WSL (4) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.003664] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.055673] WSL (1) WARNING: /usr/share/zoneinfo/Europe/Bucharest not found. Is the tzdata package installed?
[  +0.008161] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000665] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000629] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001002] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +0.001461] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000714] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000586] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000647] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +0.481468] netlink: 'init': attribute type 4 has an invalid length.
[  +0.260482] kmem.limit_in_bytes is deprecated and will be removed. Please report your usecase to linux-mm@kvack.org if you depend on this functionality.
[  +0.278922] misc dxg: dxgk: dxgkio_reserve_gpu_va: Ioctl failed: -75
[  +0.002609] misc dxg: dxgk: dxgkio_reserve_gpu_va: Ioctl failed: -75

* 
* ==> etcd [7624ffb81b16] <==
* {"level":"info","ts":"2024-04-12T09:32:17.085009Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":2329,"took":"459.727¬µs","hash":2863504673}
{"level":"info","ts":"2024-04-12T09:32:17.085074Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2863504673,"revision":2329,"compact-revision":2089}
{"level":"info","ts":"2024-04-12T09:37:17.087375Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2568}
{"level":"info","ts":"2024-04-12T09:37:17.087802Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":2568,"took":"319.007¬µs","hash":3208967297}
{"level":"info","ts":"2024-04-12T09:37:17.087828Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3208967297,"revision":2568,"compact-revision":2329}
{"level":"info","ts":"2024-04-12T09:42:17.080737Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2809}
{"level":"info","ts":"2024-04-12T09:42:17.081244Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":2809,"took":"387.692¬µs","hash":4161457523}
{"level":"info","ts":"2024-04-12T09:42:17.081274Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4161457523,"revision":2809,"compact-revision":2568}
{"level":"info","ts":"2024-04-12T09:48:35.367142Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3049}
{"level":"info","ts":"2024-04-12T09:48:35.371923Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3049,"took":"4.611666ms","hash":1071259360}
{"level":"info","ts":"2024-04-12T09:48:35.371966Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1071259360,"revision":3049,"compact-revision":2809}
{"level":"info","ts":"2024-04-12T09:53:35.371435Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3290}
{"level":"info","ts":"2024-04-12T09:53:35.371981Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3290,"took":"396.214¬µs","hash":99753653}
{"level":"info","ts":"2024-04-12T09:53:35.372016Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":99753653,"revision":3290,"compact-revision":3049}
{"level":"info","ts":"2024-04-12T11:24:48.777344Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3530}
{"level":"info","ts":"2024-04-12T11:24:48.777944Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3530,"took":"438.723¬µs","hash":10793721}
{"level":"info","ts":"2024-04-12T11:24:48.77799Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":10793721,"revision":3530,"compact-revision":3290}
{"level":"info","ts":"2024-04-12T11:26:24.505136Z","caller":"traceutil/trace.go:171","msg":"trace[697333141] transaction","detail":"{read_only:false; response_revision:3855; number_of_response:1; }","duration":"139.104233ms","start":"2024-04-12T11:26:24.366019Z","end":"2024-04-12T11:26:24.505123Z","steps":["trace[697333141] 'process raft request'  (duration: 139.038612ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:26:32.726096Z","caller":"traceutil/trace.go:171","msg":"trace[1516703995] transaction","detail":"{read_only:false; response_revision:3861; number_of_response:1; }","duration":"181.002269ms","start":"2024-04-12T11:26:32.545071Z","end":"2024-04-12T11:26:32.726073Z","steps":["trace[1516703995] 'process raft request'  (duration: 180.859601ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:26:33.849513Z","caller":"traceutil/trace.go:171","msg":"trace[1257382406] transaction","detail":"{read_only:false; response_revision:3862; number_of_response:1; }","duration":"149.524152ms","start":"2024-04-12T11:26:33.699967Z","end":"2024-04-12T11:26:33.849491Z","steps":["trace[1257382406] 'process raft request'  (duration: 149.407024ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:26:34.862469Z","caller":"traceutil/trace.go:171","msg":"trace[2131010719] transaction","detail":"{read_only:false; response_revision:3863; number_of_response:1; }","duration":"130.316078ms","start":"2024-04-12T11:26:34.732136Z","end":"2024-04-12T11:26:34.862452Z","steps":["trace[2131010719] 'process raft request'  (duration: 130.223902ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:29:48.783245Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3777}
{"level":"info","ts":"2024-04-12T11:29:48.784195Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":3777,"took":"798.094¬µs","hash":3196467705}
{"level":"info","ts":"2024-04-12T11:29:48.784226Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3196467705,"revision":3777,"compact-revision":3530}
{"level":"warn","ts":"2024-04-12T11:34:11.538806Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"140.271035ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/192.168.49.2\" ","response":"range_response_count:1 size:133"}
{"level":"info","ts":"2024-04-12T11:34:11.538906Z","caller":"traceutil/trace.go:171","msg":"trace[1627201075] range","detail":"{range_begin:/registry/masterleases/192.168.49.2; range_end:; response_count:1; response_revision:4226; }","duration":"140.378906ms","start":"2024-04-12T11:34:11.398514Z","end":"2024-04-12T11:34:11.538893Z","steps":["trace[1627201075] 'range keys from in-memory index tree'  (duration: 140.175124ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:34:48.785743Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":4017}
{"level":"info","ts":"2024-04-12T11:34:48.786379Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":4017,"took":"530.371¬µs","hash":2456540702}
{"level":"info","ts":"2024-04-12T11:34:48.786411Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2456540702,"revision":4017,"compact-revision":3777}
{"level":"info","ts":"2024-04-12T11:34:54.042958Z","caller":"traceutil/trace.go:171","msg":"trace[1165827664] transaction","detail":"{read_only:false; response_revision:4262; number_of_response:1; }","duration":"141.416216ms","start":"2024-04-12T11:34:53.90152Z","end":"2024-04-12T11:34:54.042937Z","steps":["trace[1165827664] 'process raft request'  (duration: 141.205227ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:35:21.01021Z","caller":"traceutil/trace.go:171","msg":"trace[774157237] transaction","detail":"{read_only:false; response_revision:4282; number_of_response:1; }","duration":"122.37099ms","start":"2024-04-12T11:35:20.887798Z","end":"2024-04-12T11:35:21.010169Z","steps":["trace[774157237] 'process raft request'  (duration: 121.951987ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:35:42.086378Z","caller":"traceutil/trace.go:171","msg":"trace[852328789] linearizableReadLoop","detail":"{readStateIndex:5294; appliedIndex:5293; }","duration":"158.165166ms","start":"2024-04-12T11:35:41.928199Z","end":"2024-04-12T11:35:42.086364Z","steps":["trace[852328789] 'read index received'  (duration: 158.056355ms)","trace[852328789] 'applied index is now lower than readState.Index'  (duration: 108.365¬µs)"],"step_count":2}
{"level":"info","ts":"2024-04-12T11:35:42.086492Z","caller":"traceutil/trace.go:171","msg":"trace[1545085870] transaction","detail":"{read_only:false; response_revision:4299; number_of_response:1; }","duration":"322.402732ms","start":"2024-04-12T11:35:41.764081Z","end":"2024-04-12T11:35:42.086484Z","steps":["trace[1545085870] 'process raft request'  (duration: 322.209114ms)"],"step_count":1}
{"level":"warn","ts":"2024-04-12T11:35:42.086615Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"102.542958ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-04-12T11:35:42.086705Z","caller":"traceutil/trace.go:171","msg":"trace[67384118] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:4299; }","duration":"102.6374ms","start":"2024-04-12T11:35:41.984061Z","end":"2024-04-12T11:35:42.086698Z","steps":["trace[67384118] 'agreement among raft nodes before linearized reading'  (duration: 102.529114ms)"],"step_count":1}
{"level":"warn","ts":"2024-04-12T11:35:42.086753Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-04-12T11:35:41.764068Z","time spent":"322.438923ms","remote":"127.0.0.1:49786","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":673,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" mod_revision:4290 > success:<request_put:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" value_size:600 >> failure:<request_range:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" > >"}
{"level":"warn","ts":"2024-04-12T11:35:42.086847Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"158.669719ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1109"}
{"level":"info","ts":"2024-04-12T11:35:42.086865Z","caller":"traceutil/trace.go:171","msg":"trace[466549288] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:4299; }","duration":"158.687866ms","start":"2024-04-12T11:35:41.92817Z","end":"2024-04-12T11:35:42.086858Z","steps":["trace[466549288] 'agreement among raft nodes before linearized reading'  (duration: 158.652263ms)"],"step_count":1}
{"level":"warn","ts":"2024-04-12T11:35:57.286263Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-04-12T11:35:56.917288Z","time spent":"367.660699ms","remote":"127.0.0.1:49900","response type":"/etcdserverpb.KV/Range","request count":0,"request size":48,"response count":0,"response size":29,"request content":"key:\"/registry/csidrivers/\" range_end:\"/registry/csidrivers0\" count_only:true "}
{"level":"warn","ts":"2024-04-12T11:36:24.164374Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"180.88159ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-04-12T11:36:24.164445Z","caller":"traceutil/trace.go:171","msg":"trace[1589826247] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:4332; }","duration":"180.952342ms","start":"2024-04-12T11:36:23.983475Z","end":"2024-04-12T11:36:24.164427Z","steps":["trace[1589826247] 'range keys from in-memory index tree'  (duration: 180.813598ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:36:59.235964Z","caller":"traceutil/trace.go:171","msg":"trace[2076530120] transaction","detail":"{read_only:false; response_revision:4360; number_of_response:1; }","duration":"135.837371ms","start":"2024-04-12T11:36:59.100109Z","end":"2024-04-12T11:36:59.235946Z","steps":["trace[2076530120] 'process raft request'  (duration: 135.72511ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:38:01.998507Z","caller":"traceutil/trace.go:171","msg":"trace[867404368] transaction","detail":"{read_only:false; response_revision:4410; number_of_response:1; }","duration":"170.699781ms","start":"2024-04-12T11:38:01.827791Z","end":"2024-04-12T11:38:01.99849Z","steps":["trace[867404368] 'process raft request'  (duration: 170.563499ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:38:06.196938Z","caller":"traceutil/trace.go:171","msg":"trace[1490368760] linearizableReadLoop","detail":"{readStateIndex:5436; appliedIndex:5435; }","duration":"127.158728ms","start":"2024-04-12T11:38:06.069768Z","end":"2024-04-12T11:38:06.196927Z","steps":["trace[1490368760] 'read index received'  (duration: 127.061056ms)","trace[1490368760] 'applied index is now lower than readState.Index'  (duration: 97.301¬µs)"],"step_count":2}
{"level":"info","ts":"2024-04-12T11:38:06.197154Z","caller":"traceutil/trace.go:171","msg":"trace[1166629573] transaction","detail":"{read_only:false; response_revision:4413; number_of_response:1; }","duration":"182.040344ms","start":"2024-04-12T11:38:06.015104Z","end":"2024-04-12T11:38:06.197144Z","steps":["trace[1166629573] 'process raft request'  (duration: 181.758946ms)"],"step_count":1}
{"level":"warn","ts":"2024-04-12T11:38:06.197309Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"127.56168ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/horizontalpodautoscalers/\" range_end:\"/registry/horizontalpodautoscalers0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-04-12T11:38:06.197345Z","caller":"traceutil/trace.go:171","msg":"trace[1094849896] range","detail":"{range_begin:/registry/horizontalpodautoscalers/; range_end:/registry/horizontalpodautoscalers0; response_count:0; response_revision:4413; }","duration":"127.608ms","start":"2024-04-12T11:38:06.069731Z","end":"2024-04-12T11:38:06.197339Z","steps":["trace[1094849896] 'agreement among raft nodes before linearized reading'  (duration: 127.537932ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:38:28.408617Z","caller":"traceutil/trace.go:171","msg":"trace[20938951] transaction","detail":"{read_only:false; response_revision:4431; number_of_response:1; }","duration":"117.173359ms","start":"2024-04-12T11:38:28.291425Z","end":"2024-04-12T11:38:28.408598Z","steps":["trace[20938951] 'process raft request'  (duration: 117.034082ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:39:00.765894Z","caller":"traceutil/trace.go:171","msg":"trace[767358776] transaction","detail":"{read_only:false; response_revision:4456; number_of_response:1; }","duration":"166.263905ms","start":"2024-04-12T11:39:00.599612Z","end":"2024-04-12T11:39:00.765876Z","steps":["trace[767358776] 'process raft request'  (duration: 166.132587ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:39:48.811519Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":4256}
{"level":"info","ts":"2024-04-12T11:39:48.811992Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":4256,"took":"347.729¬µs","hash":3486536430}
{"level":"info","ts":"2024-04-12T11:39:48.812031Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3486536430,"revision":4256,"compact-revision":4017}
{"level":"info","ts":"2024-04-12T11:39:51.292391Z","caller":"traceutil/trace.go:171","msg":"trace[200055258] transaction","detail":"{read_only:false; response_revision:4497; number_of_response:1; }","duration":"105.855398ms","start":"2024-04-12T11:39:51.18652Z","end":"2024-04-12T11:39:51.292375Z","steps":["trace[200055258] 'process raft request'  (duration: 105.754385ms)"],"step_count":1}
{"level":"warn","ts":"2024-04-12T11:40:17.532342Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"234.585206ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 serializable:true keys_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-04-12T11:40:17.532398Z","caller":"traceutil/trace.go:171","msg":"trace[454789196] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:4517; }","duration":"234.643346ms","start":"2024-04-12T11:40:17.297741Z","end":"2024-04-12T11:40:17.532384Z","steps":["trace[454789196] 'range keys from in-memory index tree'  (duration: 234.548156ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:40:19.753119Z","caller":"traceutil/trace.go:171","msg":"trace[1031969102] transaction","detail":"{read_only:false; response_revision:4519; number_of_response:1; }","duration":"209.006968ms","start":"2024-04-12T11:40:19.544098Z","end":"2024-04-12T11:40:19.753105Z","steps":["trace[1031969102] 'process raft request'  (duration: 208.917175ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:41:52.412882Z","caller":"traceutil/trace.go:171","msg":"trace[261849109] transaction","detail":"{read_only:false; response_revision:4594; number_of_response:1; }","duration":"113.73736ms","start":"2024-04-12T11:41:52.299131Z","end":"2024-04-12T11:41:52.412868Z","steps":["trace[261849109] 'process raft request'  (duration: 113.645833ms)"],"step_count":1}
{"level":"info","ts":"2024-04-12T11:44:48.815301Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":4494}
{"level":"info","ts":"2024-04-12T11:44:48.815917Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":4494,"took":"450.738¬µs","hash":103256393}
{"level":"info","ts":"2024-04-12T11:44:48.815957Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":103256393,"revision":4494,"compact-revision":4256}

* 
* ==> etcd [c671d022ec23] <==
* {"level":"warn","ts":"2024-04-12T08:18:59.883773Z","caller":"embed/config.go:673","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-04-12T08:18:59.884037Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2024-04-12T08:18:59.884225Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/minikube/etcd","dir-type":"member"}
{"level":"warn","ts":"2024-04-12T08:18:59.884278Z","caller":"embed/config.go:673","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-04-12T08:18:59.884297Z","caller":"embed/etcd.go:127","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-04-12T08:18:59.884421Z","caller":"embed/etcd.go:495","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-04-12T08:18:59.885049Z","caller":"embed/etcd.go:135","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2024-04-12T08:18:59.885251Z","caller":"embed/etcd.go:309","msg":"starting an etcd server","etcd-version":"3.5.9","git-sha":"bdbbde998","go-version":"go1.19.9","go-os":"linux","go-arch":"amd64","max-cpu-set":12,"max-cpu-available":12,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2024-04-12T08:18:59.976061Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"90.475733ms"}
{"level":"info","ts":"2024-04-12T08:18:59.979608Z","caller":"etcdserver/server.go:530","msg":"No snapshot found. Recovering WAL from scratch!"}
{"level":"info","ts":"2024-04-12T08:18:59.988154Z","caller":"etcdserver/raft.go:530","msg":"restarting local member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","commit-index":477}
{"level":"info","ts":"2024-04-12T08:18:59.988544Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2024-04-12T08:18:59.988629Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 2"}
{"level":"info","ts":"2024-04-12T08:18:59.988685Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 2, commit: 477, applied: 0, lastindex: 477, lastterm: 2]"}
{"level":"warn","ts":"2024-04-12T08:19:00.002537Z","caller":"auth/store.go:1238","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2024-04-12T08:19:00.066306Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":453}
{"level":"info","ts":"2024-04-12T08:19:00.078525Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2024-04-12T08:19:00.082693Z","caller":"etcdserver/corrupt.go:95","msg":"starting initial corruption check","local-member-id":"aec36adc501070cc","timeout":"7s"}
{"level":"info","ts":"2024-04-12T08:19:00.083375Z","caller":"etcdserver/corrupt.go:165","msg":"initial corruption checking passed; no corruption","local-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2024-04-12T08:19:00.083479Z","caller":"etcdserver/server.go:854","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.9","cluster-version":"to_be_decided"}
{"level":"info","ts":"2024-04-12T08:19:00.084013Z","caller":"etcdserver/server.go:754","msg":"starting initial election tick advance","election-ticks":10}
{"level":"info","ts":"2024-04-12T08:19:00.08426Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2024-04-12T08:19:00.084447Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2024-04-12T08:19:00.084495Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2024-04-12T08:19:00.08511Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2024-04-12T08:19:00.085385Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-04-12T08:19:00.08883Z","caller":"embed/etcd.go:726","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-04-12T08:19:00.089262Z","caller":"embed/etcd.go:278","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2024-04-12T08:19:00.08936Z","caller":"embed/etcd.go:855","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2024-04-12T08:19:00.089956Z","caller":"embed/etcd.go:597","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-04-12T08:19:00.090071Z","caller":"embed/etcd.go:569","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-04-12T08:19:00.094973Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2024-04-12T08:19:00.095115Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2024-04-12T08:19:01.189723Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 2"}
{"level":"info","ts":"2024-04-12T08:19:01.189789Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 2"}
{"level":"info","ts":"2024-04-12T08:19:01.189837Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2024-04-12T08:19:01.189854Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 3"}
{"level":"info","ts":"2024-04-12T08:19:01.18986Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 3"}
{"level":"info","ts":"2024-04-12T08:19:01.189875Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 3"}
{"level":"info","ts":"2024-04-12T08:19:01.189888Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 3"}
{"level":"info","ts":"2024-04-12T08:19:01.19978Z","caller":"etcdserver/server.go:2062","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2024-04-12T08:19:01.199886Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-04-12T08:19:01.200446Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-04-12T08:19:01.202028Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.49.2:2379"}
{"level":"info","ts":"2024-04-12T08:19:01.202399Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2024-04-12T08:19:01.202438Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2024-04-12T08:19:01.202609Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2024-04-12T08:19:10.489762Z","caller":"traceutil/trace.go:171","msg":"trace[1505541126] transaction","detail":"{read_only:false; response_revision:500; number_of_response:1; }","duration":"108.082063ms","start":"2024-04-12T08:19:10.381657Z","end":"2024-04-12T08:19:10.489739Z","steps":["trace[1505541126] 'process raft request'  (duration: 75.605448ms)","trace[1505541126] 'compare'  (duration: 32.356027ms)"],"step_count":2}
{"level":"info","ts":"2024-04-12T08:19:59.857342Z","caller":"traceutil/trace.go:171","msg":"trace[1696902531] transaction","detail":"{read_only:false; response_revision:567; number_of_response:1; }","duration":"114.550514ms","start":"2024-04-12T08:19:59.662046Z","end":"2024-04-12T08:19:59.776596Z","steps":["trace[1696902531] 'process raft request'  (duration: 114.366064ms)"],"step_count":1}

* 
* ==> kernel <==
*  11:47:09 up  1:27,  0 users,  load average: 0.21, 0.23, 0.16
Linux minikube 5.15.146.1-microsoft-standard-WSL2 #1 SMP Thu Jan 11 04:09:03 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.3 LTS"

* 
* ==> kube-apiserver [06ed8cfa9755] <==
* W0412 08:19:02.917444       1 genericapiserver.go:744] Skipping API admissionregistration.k8s.io/v1alpha1 because it has no resources.
I0412 08:19:02.917883       1 handler.go:232] Adding GroupVersion events.k8s.io v1 to ResourceManager
W0412 08:19:02.917914       1 genericapiserver.go:744] Skipping API events.k8s.io/v1beta1 because it has no resources.
I0412 08:19:02.970107       1 handler.go:232] Adding GroupVersion apiregistration.k8s.io v1 to ResourceManager
W0412 08:19:02.970185       1 genericapiserver.go:744] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I0412 08:19:03.813720       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0412 08:19:03.813737       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0412 08:19:03.813979       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0412 08:19:03.814552       1 secure_serving.go:213] Serving securely on [::]:8443
I0412 08:19:03.814610       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0412 08:19:03.814701       1 controller.go:78] Starting OpenAPI AggregationController
I0412 08:19:03.814741       1 available_controller.go:423] Starting AvailableConditionController
I0412 08:19:03.814746       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0412 08:19:03.814757       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0412 08:19:03.814779       1 aggregator.go:164] waiting for initial CRD sync...
I0412 08:19:03.814784       1 shared_informer.go:311] Waiting for caches to sync for cluster_authentication_trust_controller
I0412 08:19:03.815078       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0412 08:19:03.815128       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0412 08:19:03.815376       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0412 08:19:03.815403       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0412 08:19:03.815419       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0412 08:19:03.815575       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0412 08:19:03.815726       1 controller.go:116] Starting legacy_token_tracking_controller
I0412 08:19:03.815731       1 shared_informer.go:311] Waiting for caches to sync for configmaps
I0412 08:19:03.815743       1 apf_controller.go:372] Starting API Priority and Fairness config controller
I0412 08:19:03.861282       1 customresource_discovery_controller.go:289] Starting DiscoveryController
I0412 08:19:03.861509       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0412 08:19:03.863174       1 system_namespaces_controller.go:67] Starting system namespaces controller
I0412 08:19:03.863227       1 handler_discovery.go:412] Starting ResourceDiscoveryManager
I0412 08:19:03.863691       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0412 08:19:03.863731       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0412 08:19:03.863740       1 shared_informer.go:311] Waiting for caches to sync for crd-autoregister
I0412 08:19:03.863836       1 controller.go:134] Starting OpenAPI controller
I0412 08:19:03.863868       1 controller.go:85] Starting OpenAPI V3 controller
I0412 08:19:03.869393       1 establishing_controller.go:76] Starting EstablishingController
I0412 08:19:03.869411       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0412 08:19:03.869421       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0412 08:19:03.869429       1 crd_finalizer.go:266] Starting CRDFinalizer
I0412 08:19:03.961545       1 naming_controller.go:291] Starting NamingConditionController
I0412 08:19:03.962509       1 apf_controller.go:377] Running API Priority and Fairness config worker
I0412 08:19:03.968189       1 apf_controller.go:380] Running API Priority and Fairness periodic rebalancing process
I0412 08:19:03.966191       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0412 08:19:03.966508       1 shared_informer.go:318] Caches are synced for crd-autoregister
I0412 08:19:03.967188       1 shared_informer.go:318] Caches are synced for cluster_authentication_trust_controller
I0412 08:19:03.968841       1 aggregator.go:166] initial CRD sync complete...
I0412 08:19:03.968851       1 autoregister_controller.go:141] Starting autoregister controller
I0412 08:19:03.968859       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0412 08:19:03.968869       1 cache.go:39] Caches are synced for autoregister controller
I0412 08:19:03.971268       1 shared_informer.go:318] Caches are synced for node_authorizer
I0412 08:19:03.972405       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I0412 08:19:04.061776       1 shared_informer.go:318] Caches are synced for configmaps
I0412 08:19:04.061908       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0412 08:19:04.825593       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0412 08:19:07.165866       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I0412 08:19:07.177732       1 controller.go:624] quota admission added evaluator for: deployments.apps
I0412 08:19:07.218421       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I0412 08:19:07.245624       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0412 08:19:07.255414       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0412 08:19:09.034121       1 controller.go:624] quota admission added evaluator for: endpoints
I0412 08:19:17.399178       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io

* 
* ==> kube-apiserver [827129707d50] <==
* I0412 08:52:17.766664       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0412 08:52:17.766701       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0412 08:52:17.766873       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0412 08:52:17.767198       1 secure_serving.go:213] Serving securely on [::]:8443
I0412 08:52:17.767241       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0412 08:52:17.767391       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0412 08:52:17.767409       1 handler_discovery.go:412] Starting ResourceDiscoveryManager
I0412 08:52:17.767522       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0412 08:52:17.767536       1 shared_informer.go:311] Waiting for caches to sync for cluster_authentication_trust_controller
I0412 08:52:17.767591       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0412 08:52:17.767634       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0412 08:52:17.767404       1 apf_controller.go:372] Starting API Priority and Fairness config controller
I0412 08:52:17.767685       1 customresource_discovery_controller.go:289] Starting DiscoveryController
I0412 08:52:17.767701       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0412 08:52:17.767746       1 available_controller.go:423] Starting AvailableConditionController
I0412 08:52:17.767769       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0412 08:52:17.767847       1 controller.go:78] Starting OpenAPI AggregationController
I0412 08:52:17.767879       1 aggregator.go:164] waiting for initial CRD sync...
I0412 08:52:17.767889       1 controller.go:134] Starting OpenAPI controller
I0412 08:52:17.767921       1 controller.go:85] Starting OpenAPI V3 controller
I0412 08:52:17.767890       1 system_namespaces_controller.go:67] Starting system namespaces controller
I0412 08:52:17.767855       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0412 08:52:17.768005       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0412 08:52:17.768039       1 controller.go:116] Starting legacy_token_tracking_controller
I0412 08:52:17.768044       1 shared_informer.go:311] Waiting for caches to sync for configmaps
I0412 08:52:17.768131       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0412 08:52:17.767760       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0412 08:52:17.768180       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0412 08:52:17.768185       1 shared_informer.go:311] Waiting for caches to sync for crd-autoregister
I0412 08:52:17.767856       1 naming_controller.go:291] Starting NamingConditionController
I0412 08:52:17.769408       1 establishing_controller.go:76] Starting EstablishingController
I0412 08:52:17.769457       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0412 08:52:17.769486       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0412 08:52:17.769505       1 crd_finalizer.go:266] Starting CRDFinalizer
I0412 08:52:17.934712       1 shared_informer.go:318] Caches are synced for crd-autoregister
I0412 08:52:17.935644       1 aggregator.go:166] initial CRD sync complete...
I0412 08:52:17.935671       1 autoregister_controller.go:141] Starting autoregister controller
I0412 08:52:17.935679       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0412 08:52:17.937834       1 shared_informer.go:318] Caches are synced for configmaps
E0412 08:52:17.951166       1 controller.go:97] Error removing old endpoints from kubernetes service: no API server IP addresses were listed in storage, refusing to erase all endpoints for the kubernetes Service
I0412 08:52:17.967751       1 shared_informer.go:318] Caches are synced for cluster_authentication_trust_controller
I0412 08:52:17.967806       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0412 08:52:17.967837       1 apf_controller.go:377] Running API Priority and Fairness config worker
I0412 08:52:17.967875       1 apf_controller.go:380] Running API Priority and Fairness periodic rebalancing process
I0412 08:52:17.967876       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0412 08:52:18.034087       1 shared_informer.go:318] Caches are synced for node_authorizer
I0412 08:52:18.035838       1 cache.go:39] Caches are synced for autoregister controller
I0412 08:52:18.040119       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I0412 08:52:18.771564       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0412 08:52:19.515329       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I0412 08:52:19.533990       1 controller.go:624] quota admission added evaluator for: deployments.apps
I0412 08:52:19.560974       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I0412 08:52:19.586223       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0412 08:52:19.591646       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0412 08:52:30.763756       1 controller.go:624] quota admission added evaluator for: endpoints
I0412 08:52:30.790114       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
E0412 11:25:03.223658       1 authentication.go:73] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E0412 11:25:03.509876       1 authentication.go:73] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I0412 11:45:43.338165       1 alloc.go:330] "allocated clusterIPs" service="default/mytodoapp-service" clusterIPs={"IPv4":"10.107.186.61"}
I0412 11:45:56.378915       1 controller.go:624] quota admission added evaluator for: replicasets.apps

* 
* ==> kube-controller-manager [bb9a0e8df7c6] <==
* I0412 08:52:30.813485       1 shared_informer.go:318] Caches are synced for expand
I0412 08:52:30.816236       1 shared_informer.go:318] Caches are synced for ClusterRoleAggregator
I0412 08:52:30.817511       1 shared_informer.go:318] Caches are synced for node
I0412 08:52:30.817547       1 range_allocator.go:174] "Sending events to api server"
I0412 08:52:30.817559       1 range_allocator.go:178] "Starting range CIDR allocator"
I0412 08:52:30.817561       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I0412 08:52:30.817564       1 shared_informer.go:318] Caches are synced for cidrallocator
I0412 08:52:30.818668       1 shared_informer.go:318] Caches are synced for PV protection
I0412 08:52:30.822099       1 shared_informer.go:318] Caches are synced for ephemeral
I0412 08:52:30.822421       1 shared_informer.go:318] Caches are synced for attach detach
I0412 08:52:30.824386       1 shared_informer.go:318] Caches are synced for daemon sets
I0412 08:52:30.827338       1 shared_informer.go:318] Caches are synced for PVC protection
I0412 08:52:30.847688       1 shared_informer.go:318] Caches are synced for disruption
I0412 08:52:30.853222       1 shared_informer.go:318] Caches are synced for ReplicaSet
I0412 08:52:30.853518       1 shared_informer.go:318] Caches are synced for deployment
I0412 08:52:30.876556       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="23.169296ms"
I0412 08:52:30.876901       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="212.516¬µs"
I0412 08:52:30.925963       1 shared_informer.go:318] Caches are synced for TTL after finished
I0412 08:52:30.942661       1 shared_informer.go:318] Caches are synced for resource quota
I0412 08:52:30.952545       1 shared_informer.go:318] Caches are synced for crt configmap
I0412 08:52:30.973585       1 shared_informer.go:318] Caches are synced for job
I0412 08:52:30.976254       1 shared_informer.go:318] Caches are synced for cronjob
I0412 08:52:30.978367       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I0412 08:52:31.026491       1 shared_informer.go:318] Caches are synced for resource quota
I0412 08:52:31.336170       1 shared_informer.go:318] Caches are synced for garbage collector
I0412 08:52:31.427128       1 shared_informer.go:318] Caches are synced for garbage collector
I0412 08:52:31.427167       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I0412 08:52:37.294378       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="4.773623ms"
I0412 08:52:37.294462       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="40.665¬µs"
I0412 09:53:38.452231       1 cleaner.go:175] "Cleaning CSR as it is more than approvedExpiration duration old and approved." csr="csr-gngt2" approvedExpiration="1h0m0s"
E0412 11:25:03.223992       1 resource_quota_controller.go:440] failed to discover resources: the server has asked for the client to provide credentials
I0412 11:25:03.510199       1 garbagecollector.go:818] "failed to discover preferred resources" error="the server has asked for the client to provide credentials"
I0412 11:45:56.382553       1 event.go:307] "Event occurred" object="default/mytodoapp-deployment" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set mytodoapp-deployment-9b897698f to 3"
I0412 11:45:56.395680       1 event.go:307] "Event occurred" object="default/mytodoapp-deployment-9b897698f" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: mytodoapp-deployment-9b897698f-ntsj2"
I0412 11:45:56.401946       1 event.go:307] "Event occurred" object="default/mytodoapp-deployment-9b897698f" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: mytodoapp-deployment-9b897698f-bbwvg"
I0412 11:45:56.404164       1 event.go:307] "Event occurred" object="default/mytodoapp-deployment-9b897698f" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: mytodoapp-deployment-9b897698f-vf5jt"
I0412 11:45:56.418211       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="35.910132ms"
I0412 11:45:56.433756       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="15.483209ms"
I0412 11:45:56.433832       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="43.492¬µs"
I0412 11:45:56.433855       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="15.034¬µs"
I0412 11:45:56.444183       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="57.121¬µs"
I0412 11:45:58.234744       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="49.378¬µs"
I0412 11:45:59.241930       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="1.8208ms"
I0412 11:45:59.248203       1 endpointslice_controller.go:310] "Error syncing endpoint slices for service, retrying" key="default/mytodoapp-service" err="EndpointSlice informer cache is out of date"
I0412 11:45:59.250139       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="247.687¬µs"
I0412 11:45:59.258703       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="51.324¬µs"
I0412 11:46:10.086663       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="65.673¬µs"
I0412 11:46:11.087403       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="56.022¬µs"
I0412 11:46:24.088188       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="58.006¬µs"
I0412 11:46:25.086016       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="72.537¬µs"
I0412 11:46:27.081919       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="68.31¬µs"
I0412 11:46:36.080109       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="43.476¬µs"
I0412 11:46:37.082813       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="34.082¬µs"
I0412 11:46:40.087095       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="49.545¬µs"
I0412 11:46:48.085181       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="47.227¬µs"
I0412 11:46:50.090354       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="33.189¬µs"
I0412 11:46:55.085358       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="35.345¬µs"
I0412 11:46:59.087777       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="36.7¬µs"
I0412 11:47:03.085367       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="45.228¬µs"
I0412 11:47:09.079691       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/mytodoapp-deployment-9b897698f" duration="47.216¬µs"

* 
* ==> kube-controller-manager [df0cb92901ed] <==
* I0412 08:19:17.037579       1 controllermanager.go:642] "Started controller" controller="pod-garbage-collector-controller"
I0412 08:19:17.037659       1 gc_controller.go:103] "Starting GC controller"
I0412 08:19:17.037685       1 shared_informer.go:311] Waiting for caches to sync for GC
I0412 08:19:17.039755       1 controllermanager.go:642] "Started controller" controller="serviceaccount-controller"
I0412 08:19:17.039812       1 serviceaccounts_controller.go:111] "Starting service account controller"
I0412 08:19:17.039818       1 shared_informer.go:311] Waiting for caches to sync for service account
I0412 08:19:17.089417       1 controllermanager.go:642] "Started controller" controller="certificatesigningrequest-cleaner-controller"
I0412 08:19:17.089521       1 cleaner.go:83] "Starting CSR cleaner controller"
I0412 08:19:17.095460       1 shared_informer.go:311] Waiting for caches to sync for resource quota
I0412 08:19:17.113262       1 shared_informer.go:318] Caches are synced for TTL after finished
I0412 08:19:17.118617       1 shared_informer.go:311] Waiting for caches to sync for garbage collector
I0412 08:19:17.122503       1 shared_informer.go:318] Caches are synced for namespace
I0412 08:19:17.125424       1 shared_informer.go:318] Caches are synced for ReplicaSet
I0412 08:19:17.125590       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="93.002¬µs"
I0412 08:19:17.126846       1 shared_informer.go:318] Caches are synced for HPA
I0412 08:19:17.126898       1 shared_informer.go:318] Caches are synced for stateful set
I0412 08:19:17.128222       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I0412 08:19:17.131142       1 shared_informer.go:318] Caches are synced for ClusterRoleAggregator
I0412 08:19:17.131484       1 shared_informer.go:318] Caches are synced for disruption
I0412 08:19:17.136074       1 shared_informer.go:318] Caches are synced for expand
I0412 08:19:17.140895       1 shared_informer.go:318] Caches are synced for service account
I0412 08:19:17.161422       1 shared_informer.go:318] Caches are synced for ReplicationController
I0412 08:19:17.184608       1 shared_informer.go:318] Caches are synced for resource quota
I0412 08:19:17.187455       1 shared_informer.go:318] Caches are synced for job
I0412 08:19:17.190215       1 shared_informer.go:318] Caches are synced for deployment
I0412 08:19:17.192422       1 shared_informer.go:318] Caches are synced for cronjob
I0412 08:19:17.195807       1 shared_informer.go:318] Caches are synced for resource quota
I0412 08:19:17.196031       1 shared_informer.go:318] Caches are synced for PVC protection
I0412 08:19:17.200507       1 actual_state_of_world.go:547] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0412 08:19:17.202122       1 shared_informer.go:318] Caches are synced for PV protection
I0412 08:19:17.203479       1 shared_informer.go:318] Caches are synced for TTL
I0412 08:19:17.205617       1 shared_informer.go:318] Caches are synced for crt configmap
I0412 08:19:17.207930       1 shared_informer.go:318] Caches are synced for endpoint
I0412 08:19:17.210613       1 shared_informer.go:318] Caches are synced for ephemeral
I0412 08:19:17.210801       1 shared_informer.go:318] Caches are synced for endpoint_slice
I0412 08:19:17.213141       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I0412 08:19:17.238065       1 shared_informer.go:318] Caches are synced for GC
I0412 08:19:17.258235       1 shared_informer.go:318] Caches are synced for node
I0412 08:19:17.258501       1 range_allocator.go:174] "Sending events to api server"
I0412 08:19:17.258537       1 range_allocator.go:178] "Starting range CIDR allocator"
I0412 08:19:17.258569       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I0412 08:19:17.258579       1 shared_informer.go:318] Caches are synced for cidrallocator
I0412 08:19:17.264635       1 shared_informer.go:318] Caches are synced for daemon sets
I0412 08:19:17.290006       1 shared_informer.go:318] Caches are synced for taint
I0412 08:19:17.290328       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0412 08:19:17.290329       1 node_lifecycle_controller.go:1225] "Initializing eviction metric for zone" zone=""
I0412 08:19:17.290393       1 taint_manager.go:211] "Sending events to api server"
I0412 08:19:17.290504       1 node_lifecycle_controller.go:877] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I0412 08:19:17.290649       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0412 08:19:17.290672       1 node_lifecycle_controller.go:1071] "Controller detected that zone is now in new state" zone="" newState="Normal"
I0412 08:19:17.298494       1 shared_informer.go:318] Caches are synced for persistent volume
I0412 08:19:17.335058       1 shared_informer.go:318] Caches are synced for attach detach
I0412 08:19:17.370240       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-serving
I0412 08:19:17.371100       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-client
I0412 08:19:17.373237       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0412 08:19:17.374457       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-legacy-unknown
I0412 08:19:17.379050       1 shared_informer.go:318] Caches are synced for certificate-csrapproving
I0412 08:19:17.701444       1 shared_informer.go:318] Caches are synced for garbage collector
I0412 08:19:17.701567       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I0412 08:19:17.719693       1 shared_informer.go:318] Caches are synced for garbage collector

* 
* ==> kube-proxy [0170b62d1a5b] <==
* I0412 08:52:19.552833       1 server_others.go:69] "Using iptables proxy"
I0412 08:52:19.573555       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0412 08:52:19.605737       1 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0412 08:52:19.607271       1 server_others.go:152] "Using iptables Proxier"
I0412 08:52:19.607312       1 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0412 08:52:19.607327       1 server_others.go:438] "Defaulting to no-op detect-local"
I0412 08:52:19.608093       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0412 08:52:19.608780       1 server.go:846] "Version info" version="v1.28.3"
I0412 08:52:19.608849       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0412 08:52:19.612351       1 config.go:188] "Starting service config controller"
I0412 08:52:19.612393       1 shared_informer.go:311] Waiting for caches to sync for service config
I0412 08:52:19.612390       1 config.go:97] "Starting endpoint slice config controller"
I0412 08:52:19.612410       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0412 08:52:19.612450       1 config.go:315] "Starting node config controller"
I0412 08:52:19.612462       1 shared_informer.go:311] Waiting for caches to sync for node config
I0412 08:52:19.713549       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0412 08:52:19.713591       1 shared_informer.go:318] Caches are synced for node config
I0412 08:52:19.713606       1 shared_informer.go:318] Caches are synced for service config

* 
* ==> kube-proxy [3710f7734d7c] <==
* I0412 08:19:06.384911       1 server_others.go:69] "Using iptables proxy"
I0412 08:19:06.481491       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0412 08:19:06.519533       1 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0412 08:19:06.562083       1 server_others.go:152] "Using iptables Proxier"
I0412 08:19:06.562211       1 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0412 08:19:06.562224       1 server_others.go:438] "Defaulting to no-op detect-local"
I0412 08:19:06.562280       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0412 08:19:06.562766       1 server.go:846] "Version info" version="v1.28.3"
I0412 08:19:06.562837       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0412 08:19:06.569856       1 config.go:188] "Starting service config controller"
I0412 08:19:06.569935       1 shared_informer.go:311] Waiting for caches to sync for service config
I0412 08:19:06.569971       1 config.go:315] "Starting node config controller"
I0412 08:19:06.570016       1 shared_informer.go:311] Waiting for caches to sync for node config
I0412 08:19:06.570432       1 config.go:97] "Starting endpoint slice config controller"
I0412 08:19:06.570451       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0412 08:19:06.670781       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0412 08:19:06.670868       1 shared_informer.go:318] Caches are synced for node config
I0412 08:19:06.670893       1 shared_informer.go:318] Caches are synced for service config

* 
* ==> kube-scheduler [2aa3a729c51a] <==
* I0412 08:19:00.984365       1 serving.go:348] Generated self-signed cert in-memory
I0412 08:19:04.072467       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.28.3"
I0412 08:19:04.072529       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0412 08:19:04.086809       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0412 08:19:04.087024       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0412 08:19:04.087065       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0412 08:19:04.087065       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0412 08:19:04.087225       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
I0412 08:19:04.087268       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0412 08:19:04.091177       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0412 08:19:04.091905       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0412 08:19:04.188276       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0412 08:19:04.188404       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
I0412 08:19:04.188518       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file

* 
* ==> kube-scheduler [8f1d95252ddf] <==
* I0412 08:52:15.933894       1 serving.go:348] Generated self-signed cert in-memory
I0412 08:52:17.965023       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.28.3"
I0412 08:52:17.965119       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0412 08:52:17.969251       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0412 08:52:17.969271       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0412 08:52:17.969313       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
I0412 08:52:17.969680       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0412 08:52:17.969750       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0412 08:52:17.970182       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0412 08:52:17.970221       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0412 08:52:17.970182       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0412 08:52:18.070939       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0412 08:52:18.070985       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
I0412 08:52:18.070998       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* Apr 12 11:39:46 minikube kubelet[1606]: W0412 11:39:46.104493    1606 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 12 11:44:46 minikube kubelet[1606]: W0412 11:44:46.097387    1606 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 12 11:45:56 minikube kubelet[1606]: I0412 11:45:56.407629    1606 topology_manager.go:215] "Topology Admit Handler" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4" podNamespace="default" podName="mytodoapp-deployment-9b897698f-ntsj2"
Apr 12 11:45:56 minikube kubelet[1606]: I0412 11:45:56.415822    1606 topology_manager.go:215] "Topology Admit Handler" podUID="7236651d-9c51-421f-87b9-2a01660541c0" podNamespace="default" podName="mytodoapp-deployment-9b897698f-bbwvg"
Apr 12 11:45:56 minikube kubelet[1606]: I0412 11:45:56.416016    1606 topology_manager.go:215] "Topology Admit Handler" podUID="9109885f-dcb1-4aae-9925-aba930266c77" podNamespace="default" podName="mytodoapp-deployment-9b897698f-vf5jt"
Apr 12 11:45:56 minikube kubelet[1606]: I0412 11:45:56.510750    1606 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-cfzvn\" (UniqueName: \"kubernetes.io/projected/9109885f-dcb1-4aae-9925-aba930266c77-kube-api-access-cfzvn\") pod \"mytodoapp-deployment-9b897698f-vf5jt\" (UID: \"9109885f-dcb1-4aae-9925-aba930266c77\") " pod="default/mytodoapp-deployment-9b897698f-vf5jt"
Apr 12 11:45:56 minikube kubelet[1606]: I0412 11:45:56.510799    1606 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-68kfn\" (UniqueName: \"kubernetes.io/projected/6045cfb1-29ff-4636-83ef-052cbb05aab4-kube-api-access-68kfn\") pod \"mytodoapp-deployment-9b897698f-ntsj2\" (UID: \"6045cfb1-29ff-4636-83ef-052cbb05aab4\") " pod="default/mytodoapp-deployment-9b897698f-ntsj2"
Apr 12 11:45:56 minikube kubelet[1606]: I0412 11:45:56.510811    1606 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-z9vp7\" (UniqueName: \"kubernetes.io/projected/7236651d-9c51-421f-87b9-2a01660541c0-kube-api-access-z9vp7\") pod \"mytodoapp-deployment-9b897698f-bbwvg\" (UID: \"7236651d-9c51-421f-87b9-2a01660541c0\") " pod="default/mytodoapp-deployment-9b897698f-bbwvg"
Apr 12 11:45:57 minikube kubelet[1606]: I0412 11:45:57.140934    1606 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="1582ceb753c19b2eed5903f464e327f3dfc23ed5c8f9f7f363ac5902e108e09a"
Apr 12 11:45:57 minikube kubelet[1606]: I0412 11:45:57.194896    1606 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="5807f84d43807d8558ff3c6058db9fc292b2623ddd2532240c04c3a3a08bc01c"
Apr 12 11:45:57 minikube kubelet[1606]: I0412 11:45:57.199383    1606 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="f69a43742994255caca2bf9dee8b503cddb3ea4aff7089164afdfb720b51ee0b"
Apr 12 11:45:57 minikube kubelet[1606]: E0412 11:45:57.848242    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:45:57 minikube kubelet[1606]: E0412 11:45:57.848288    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:45:57 minikube kubelet[1606]: E0412 11:45:57.851008    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cfzvn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-vf5jt_default(9109885f-dcb1-4aae-9925-aba930266c77): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:45:57 minikube kubelet[1606]: E0412 11:45:57.851067    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.219799    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.401517    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.401568    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.401758    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-68kfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-ntsj2_default(6045cfb1-29ff-4636-83ef-052cbb05aab4): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.401798    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.967578    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.967646    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.967759    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z9vp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-bbwvg_default(7236651d-9c51-421f-87b9-2a01660541c0): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:45:58 minikube kubelet[1606]: E0412 11:45:58.967808    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"
Apr 12 11:45:59 minikube kubelet[1606]: E0412 11:45:59.230116    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:45:59 minikube kubelet[1606]: E0412 11:45:59.230438    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"
Apr 12 11:45:59 minikube kubelet[1606]: E0412 11:45:59.230475    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:46:10 minikube kubelet[1606]: E0412 11:46:10.648600    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:10 minikube kubelet[1606]: E0412 11:46:10.648638    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:10 minikube kubelet[1606]: E0412 11:46:10.648702    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-68kfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-ntsj2_default(6045cfb1-29ff-4636-83ef-052cbb05aab4): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:46:10 minikube kubelet[1606]: E0412 11:46:10.648725    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:46:11 minikube kubelet[1606]: E0412 11:46:11.736148    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:11 minikube kubelet[1606]: E0412 11:46:11.736184    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:11 minikube kubelet[1606]: E0412 11:46:11.736241    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z9vp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-bbwvg_default(7236651d-9c51-421f-87b9-2a01660541c0): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:46:11 minikube kubelet[1606]: E0412 11:46:11.736264    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"
Apr 12 11:46:12 minikube kubelet[1606]: E0412 11:46:12.609683    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:12 minikube kubelet[1606]: E0412 11:46:12.609747    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:12 minikube kubelet[1606]: E0412 11:46:12.609836    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cfzvn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-vf5jt_default(9109885f-dcb1-4aae-9925-aba930266c77): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:46:12 minikube kubelet[1606]: E0412 11:46:12.609867    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:46:24 minikube kubelet[1606]: E0412 11:46:24.078907    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:46:25 minikube kubelet[1606]: E0412 11:46:25.074359    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:46:27 minikube kubelet[1606]: E0412 11:46:27.072468    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"
Apr 12 11:46:36 minikube kubelet[1606]: E0412 11:46:36.612402    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:36 minikube kubelet[1606]: E0412 11:46:36.612449    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:36 minikube kubelet[1606]: E0412 11:46:36.612516    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-68kfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-ntsj2_default(6045cfb1-29ff-4636-83ef-052cbb05aab4): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:46:36 minikube kubelet[1606]: E0412 11:46:36.612549    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:46:37 minikube kubelet[1606]: E0412 11:46:37.627703    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:37 minikube kubelet[1606]: E0412 11:46:37.627750    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:37 minikube kubelet[1606]: E0412 11:46:37.627811    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cfzvn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-vf5jt_default(9109885f-dcb1-4aae-9925-aba930266c77): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:46:37 minikube kubelet[1606]: E0412 11:46:37.628193    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:46:40 minikube kubelet[1606]: E0412 11:46:40.643073    1606 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:40 minikube kubelet[1606]: E0412 11:46:40.643128    1606 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: Head \"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\": no basic auth credentials" image="381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest"
Apr 12 11:46:40 minikube kubelet[1606]: E0412 11:46:40.643216    1606 kuberuntime_manager.go:1256] container &Container{Name:mytodoapp,Image:381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:3000,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z9vp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod mytodoapp-deployment-9b897698f-bbwvg_default(7236651d-9c51-421f-87b9-2a01660541c0): ErrImagePull: Error response from daemon: Head "https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest": no basic auth credentials
Apr 12 11:46:40 minikube kubelet[1606]: E0412 11:46:40.643251    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ErrImagePull: \"Error response from daemon: Head \\\"https://381492073646.dkr.ecr.us-east-1.amazonaws.com/v2/mytodoapp-ecr/manifests/latest\\\": no basic auth credentials\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"
Apr 12 11:46:48 minikube kubelet[1606]: E0412 11:46:48.075654    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:46:50 minikube kubelet[1606]: E0412 11:46:50.076298    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:46:55 minikube kubelet[1606]: E0412 11:46:55.072977    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"
Apr 12 11:46:59 minikube kubelet[1606]: E0412 11:46:59.075167    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-ntsj2" podUID="6045cfb1-29ff-4636-83ef-052cbb05aab4"
Apr 12 11:47:03 minikube kubelet[1606]: E0412 11:47:03.073947    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-vf5jt" podUID="9109885f-dcb1-4aae-9925-aba930266c77"
Apr 12 11:47:09 minikube kubelet[1606]: E0412 11:47:09.072318    1606 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mytodoapp\" with ImagePullBackOff: \"Back-off pulling image \\\"381492073646.dkr.ecr.us-east-1.amazonaws.com/mytodoapp-ecr:latest\\\"\"" pod="default/mytodoapp-deployment-9b897698f-bbwvg" podUID="7236651d-9c51-421f-87b9-2a01660541c0"

* 
* ==> storage-provisioner [0a29f0b3fbd2] <==
* I0412 08:52:44.489086       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0412 08:52:44.496262       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0412 08:52:44.496525       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0412 08:53:01.901555       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0412 08:53:01.901727       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8d5d879b-b497-46d7-b1be-ac1d587d50e2!
I0412 08:53:01.901836       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"7aae0e64-682f-467e-b619-564bf8ea328b", APIVersion:"v1", ResourceVersion:"685", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_8d5d879b-b497-46d7-b1be-ac1d587d50e2 became leader
I0412 08:53:02.004063       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_8d5d879b-b497-46d7-b1be-ac1d587d50e2!

* 
* ==> storage-provisioner [18f1d25b721b] <==
* I0412 08:52:19.458611       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0412 08:52:29.469314       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": net/http: TLS handshake timeout

